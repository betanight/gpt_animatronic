{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practicing with Matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be testing and trying out different methods that can be used to train and enhance our model to be able to effectively learn from a large file. First we will start off with small books, and then move on from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c3/gd7dympn2rq3xs5m82fgbzz80000gn/T/ipykernel_42937/923978391.py:6: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = 'mps' if torch.has_mps else 'cpu'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Check for MPS support (for Metal GPU acceleration on macOS)\n",
    "device = 'mps' if torch.has_mps else 'cpu'\n",
    "print(device)\n",
    "\n",
    "block_size = 16  # increase block size to allow more context\n",
    "batch_size = 32  # increase batch size for better gradient estimates\n",
    "max_iters = 5000  # increase max iterations for more training time\n",
    "learning_rate = 5e-4  # try a slightly higher learning rate\n",
    "eval_iters = 100  # evaluate more frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just shows that you have successfully installed Metal on your device. As long as it shows mps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '&', '(', ')', ',', '-', '.', '0', '1', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "with open('wonderful_wizard_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! 73 is the amount of each individual character shown in this whole book! Later on we will convert each one into a token and then further down we will embedden them into matrices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([72, 34, 48, 45,  1, 37, 55, 54, 44, 45, 58, 46, 61, 52,  1, 37, 49, 66,\n",
      "        41, 58, 44,  1, 55, 46,  1, 29, 66,  0,  0, 42, 65,  1, 26,  8,  1, 20,\n",
      "        58, 41, 54, 51,  1, 16, 41, 61, 53,  0,  0,  0, 34, 48, 49, 59,  1, 42,\n",
      "        55, 55, 51,  1, 49, 59,  1, 44, 45, 44, 49, 43, 41, 60, 45, 44,  1, 60,\n",
      "        55,  1, 53, 65,  1, 47, 55, 55, 44,  1, 46, 58, 49, 45, 54, 44,  1,  3,\n",
      "         1, 43, 55, 53, 58, 41, 44, 45,  0, 27])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how now each letter, space, symbol, indent, etc. now has its own classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([64, 30])\n",
      "tensor([[0.0139, 0.6806, 0.7500,  ..., 0.8056, 0.6806, 0.7500],\n",
      "        [0.8750, 0.6667, 0.5694,  ..., 0.6667, 0.9028, 0.0139],\n",
      "        [0.0139, 0.6667, 0.6250,  ..., 0.5694, 0.7500, 0.8333],\n",
      "        ...,\n",
      "        [0.6667, 0.5694, 0.6111,  ..., 0.6667, 0.7639, 0.8472],\n",
      "        [0.8750, 0.0833, 0.0139,  ..., 0.0139, 0.6389, 0.6806],\n",
      "        [0.6111, 0.6250, 0.7500,  ..., 0.6667, 0.6250, 0.0139]],\n",
      "       device='mps:0')\n",
      "torch.Size([64, 30])\n",
      "targets:\n",
      "tensor([[0.6806, 0.7500, 0.0139,  ..., 0.6806, 0.7500, 0.6528],\n",
      "        [0.6667, 0.5694, 0.8333,  ..., 0.9028, 0.0139, 0.8750],\n",
      "        [0.6667, 0.6250, 0.8056,  ..., 0.7500, 0.8333, 0.0139],\n",
      "        ...,\n",
      "        [0.5694, 0.6111, 0.0139,  ..., 0.7639, 0.8472, 0.8056],\n",
      "        [0.0833, 0.0139, 0.8750,  ..., 0.6389, 0.6806, 0.6528],\n",
      "        [0.6250, 0.7500, 0.0139,  ..., 0.6250, 0.0139, 0.6111]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "block_size = 30  # Sequence length (number of tokens per sequence)\n",
    "batch_size = 64  # Number of sequences per batch\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Compute min/max from training data only\n",
    "min_val, max_val = train_data.min(), train_data.max()\n",
    "\n",
    "# Normalize train and validation data (using train's min/max for consistency)\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "val_data = (val_data - min_val) / (max_val - min_val)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # Select starting points of sequences\n",
    "\n",
    "    # Create sequences and targets\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])  # shape: (batch_size, block_size)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  # shape: (batch_size, block_size)\n",
    "\n",
    "    # Moving data to device (GPU if available)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# Get a batch\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x.shape)  # Should be (batch_size, block_size)\n",
    "print(x)\n",
    "print(y.shape)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now split. 80 percent train and 20% validation. the get_batch function takes either the **'train'** or **'val'** sets and gets random bunches from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about model not being defined yet, we first need to class the Birgramlanguange model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass BigramLanguageModel(nn.Module):\\n    def __init__(self, vocab_size):\\n        super().__init__()\\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\\n        \\n    def forward(self, index, targets=None):\\n        logits = self.token_embedding_table(index)\\n        \\n        if targets is None:\\n            loss = None\\n        else:\\n            B, T, C = logits.shape\\n            logits = logits.view(B * T, C)\\n            targets = targets.view(B * T)\\n            loss = F.cross_entropy(logits, targets)\\n        \\n        return logits, loss\\n    \\n    def generate(self, index, max_new_tokens):\\n        # index is (B, T) array of indices in the current context\\n        for _ in range(max_new_tokens):\\n            # get the predictions\\n            logits, loss = self.forward(index)\\n            # focus only on the last time step\\n            logits = logits[:, -1, :]  # becomes (B, C)\\n            # apply softmax to get probabilities\\n            probs = F.softmax(logits, dim=-1)  # (B, C)\\n            # sample from the distribution\\n            index_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\\n            # append sampled index to the running sequence\\n            index = torch.cat((index, index_next), dim=1)  # (B, T+1)\\n        return index\\n\\nmodel = BigramLanguageModel(vocab_size)\\nm = model.to(device)\\n\\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\\ngenerated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\\nprint(generated_chars)\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1)  # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Loss: 0.9483\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SequencePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(SequencePredictionModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with correct input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to output the prediction\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure the input is in float32 format\n",
    "        x = x.float()\n",
    "\n",
    "        # If the input is 2D (batch_size, sequence_length), assume 1 feature per time step\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)  # Add a feature dimension, making it (batch_size, sequence_length, 1)\n",
    "\n",
    "        # Ensure the input has the correct shape for the LSTM: (batch_size, sequence_length, 9)\n",
    "        if x.size(-1) == 1:  # Check if the input has 1 feature per timestep\n",
    "            x = x.expand(-1, -1, 9)  # Expand to 9 features per timestep\n",
    "\n",
    "        # Check input shape for debugging\n",
    "        print(f\"Input shape for LSTM: {x.shape}\")\n",
    "\n",
    "        # Initialize hidden state with zeros (set to float32)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float32).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float32).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Only take the output from the last time step\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer output\n",
    "        out = self.fc(last_time_step_out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Example of model usage:\n",
    "input_size = 9  # Number of features per time step (adjust as per data)\n",
    "hidden_size = 128  # Hidden size of the LSTM layer\n",
    "output_size = 16  # Output size (adjust based on target)\n",
    "\n",
    "# Creating the model\n",
    "model = SequencePredictionModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Dummy input with 3D shape (batch_size=64, sequence_length=30, input_size=9)\n",
    "x = torch.randn(64, 30, 9)  # 64 sequences, 30 timesteps per sequence\n",
    "\n",
    "# Dummy target (y) with 2D shape (batch_size=64, output_size=16)\n",
    "y = torch.randn(64, 16)  # Target with 16 values per sequence\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "# Compute the loss\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss (for regression tasks)\n",
    "loss = criterion(output, y)\n",
    "\n",
    "# Backward pass and optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=1 - Loss: 1.0677\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=1 - Loss: 1.0652\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=1 - Loss: 1.0627\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=1 - Loss: 1.0603\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=1 - Loss: 1.0579\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=1 - Loss: 1.0555\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=1 - Loss: 1.0532\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=1 - Loss: 1.0509\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=1 - Loss: 1.0486\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=1 - Loss: 1.0462\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=1 - Loss: 1.0439\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=1 - Loss: 1.0416\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=1 - Loss: 1.0393\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=1 - Loss: 1.0369\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=1 - Loss: 1.0345\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=1 - Loss: 1.0321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=1 - Loss: 1.0297\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=1 - Loss: 1.0272\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=1 - Loss: 1.0246\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=1 - Loss: 1.0220\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=1 - Loss: 1.0193\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=1 - Loss: 1.0166\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=1 - Loss: 1.0137\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=1 - Loss: 1.0108\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=1 - Loss: 1.0077\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=1 - Loss: 1.0046\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=1 - Loss: 1.0013\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=1 - Loss: 0.9978\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=1 - Loss: 0.9942\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=1 - Loss: 0.9904\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=1 - Loss: 0.9864\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=1 - Loss: 0.9822\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=1 - Loss: 0.9777\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=1 - Loss: 0.9730\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=1 - Loss: 0.9679\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=1 - Loss: 0.9625\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=1 - Loss: 0.9568\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=1 - Loss: 0.9506\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=1 - Loss: 0.9441\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=1 - Loss: 0.9371\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=1 - Loss: 0.9297\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=1 - Loss: 0.9220\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=1 - Loss: 0.9142\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=1 - Loss: 0.9063\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=1 - Loss: 0.8983\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=1 - Loss: 0.8900\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=1 - Loss: 0.8812\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=1 - Loss: 0.8719\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=1 - Loss: 0.8620\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=1 - Loss: 0.8517\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=1 - Loss: 0.8411\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=1 - Loss: 0.8302\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=1 - Loss: 0.8191\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=1 - Loss: 0.8076\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=1 - Loss: 0.7960\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=1 - Loss: 0.7838\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=1 - Loss: 0.7711\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=1 - Loss: 0.7579\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=1 - Loss: 0.7449\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=1 - Loss: 0.7312\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=1 - Loss: 0.7174\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=1 - Loss: 0.7034\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=1 - Loss: 0.6903\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=1 - Loss: 0.6804\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=1 - Loss: 0.6668\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=1 - Loss: 0.6535\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=1 - Loss: 0.6436\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=1 - Loss: 0.6311\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=1 - Loss: 0.6198\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=1 - Loss: 0.6088\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=1 - Loss: 0.5974\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=1 - Loss: 0.5877\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=1 - Loss: 0.5765\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=1 - Loss: 0.5667\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=1 - Loss: 0.5562\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=1 - Loss: 0.5450\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=1 - Loss: 0.5354\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=1 - Loss: 0.5250\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=1 - Loss: 0.5149\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=1 - Loss: 0.5058\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=1 - Loss: 0.4973\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=1 - Loss: 0.4933\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=1 - Loss: 0.4862\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=1 - Loss: 0.4698\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=1 - Loss: 0.4680\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=1 - Loss: 0.4588\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=1 - Loss: 0.4498\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=1 - Loss: 0.4429\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=1 - Loss: 0.4332\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=1 - Loss: 0.4266\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=1 - Loss: 0.4173\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=1 - Loss: 0.4118\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=1 - Loss: 0.4036\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=1 - Loss: 0.3963\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=1 - Loss: 0.3889\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=1 - Loss: 0.3815\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=1 - Loss: 0.3751\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=1 - Loss: 0.3669\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=1 - Loss: 0.3614\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=1 - Loss: 0.3540\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=2 - Loss: 1.0713\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=2 - Loss: 1.0693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=2 - Loss: 1.0675\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=2 - Loss: 1.0657\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=2 - Loss: 1.0639\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=2 - Loss: 1.0622\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=2 - Loss: 1.0606\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=2 - Loss: 1.0589\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=2 - Loss: 1.0573\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=2 - Loss: 1.0556\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=2 - Loss: 1.0540\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=2 - Loss: 1.0524\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=2 - Loss: 1.0509\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=2 - Loss: 1.0494\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=2 - Loss: 1.0479\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=2 - Loss: 1.0465\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=2 - Loss: 1.0449\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=2 - Loss: 1.0432\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=2 - Loss: 1.0413\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=2 - Loss: 1.0390\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=2 - Loss: 1.0364\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=2 - Loss: 1.0335\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=2 - Loss: 1.0303\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=2 - Loss: 1.0268\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=2 - Loss: 1.0229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=2 - Loss: 1.0185\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=2 - Loss: 1.0135\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=2 - Loss: 1.0080\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=2 - Loss: 1.0020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=2 - Loss: 0.9958\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=2 - Loss: 0.9896\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=2 - Loss: 0.9837\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=2 - Loss: 0.9771\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=2 - Loss: 0.9691\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=2 - Loss: 0.9597\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=2 - Loss: 0.9497\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=2 - Loss: 0.9394\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=2 - Loss: 0.9292\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=2 - Loss: 0.9201\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=2 - Loss: 0.9120\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=2 - Loss: 0.9022\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=2 - Loss: 0.8907\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=2 - Loss: 0.8775\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=2 - Loss: 0.8645\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=2 - Loss: 0.8511\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=2 - Loss: 0.8384\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=2 - Loss: 0.8361\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=2 - Loss: 0.8307\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=2 - Loss: 0.8065\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=2 - Loss: 0.8020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=2 - Loss: 0.7899\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=2 - Loss: 0.7742\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=2 - Loss: 0.7644\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=2 - Loss: 0.7502\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=2 - Loss: 0.7402\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=2 - Loss: 0.7258\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=2 - Loss: 0.7151\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=2 - Loss: 0.6999\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=2 - Loss: 0.6885\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=2 - Loss: 0.6764\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=2 - Loss: 0.6621\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=2 - Loss: 0.6499\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=2 - Loss: 0.6366\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=2 - Loss: 0.6216\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=2 - Loss: 0.6113\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=2 - Loss: 0.5951\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=2 - Loss: 0.5817\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=2 - Loss: 0.5692\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=2 - Loss: 0.5537\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=2 - Loss: 0.5417\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=2 - Loss: 0.5294\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=2 - Loss: 0.5150\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=2 - Loss: 0.5043\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=2 - Loss: 0.4903\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=2 - Loss: 0.4781\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=2 - Loss: 0.4644\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=2 - Loss: 0.4539\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=2 - Loss: 0.4427\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=2 - Loss: 0.4438\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=2 - Loss: 0.4546\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=2 - Loss: 0.4130\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=2 - Loss: 0.4243\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=2 - Loss: 0.3944\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=2 - Loss: 0.3996\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=2 - Loss: 0.3739\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=2 - Loss: 0.3749\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=2 - Loss: 0.3552\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=2 - Loss: 0.3520\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=2 - Loss: 0.3408\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=2 - Loss: 0.3289\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=2 - Loss: 0.3224\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=2 - Loss: 0.3105\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=2 - Loss: 0.3022\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=2 - Loss: 0.2939\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=2 - Loss: 0.2821\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=2 - Loss: 0.2775\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=2 - Loss: 0.2660\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=2 - Loss: 0.2618\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=2 - Loss: 0.2516\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=2 - Loss: 0.2477\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=3 - Loss: 1.0724\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=3 - Loss: 1.0703\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=3 - Loss: 1.0684\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=3 - Loss: 1.0667\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=3 - Loss: 1.0651\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=3 - Loss: 1.0636\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=3 - Loss: 1.0621\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=3 - Loss: 1.0607\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=3 - Loss: 1.0595\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=3 - Loss: 1.0583\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=3 - Loss: 1.0573\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=3 - Loss: 1.0564\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=3 - Loss: 1.0557\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=3 - Loss: 1.0551\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=3 - Loss: 1.0544\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=3 - Loss: 1.0535\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=3 - Loss: 1.0524\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=3 - Loss: 1.0511\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=3 - Loss: 1.0495\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=3 - Loss: 1.0478\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=3 - Loss: 1.0457\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=3 - Loss: 1.0434\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=3 - Loss: 1.0406\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=3 - Loss: 1.0372\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=3 - Loss: 1.0331\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=3 - Loss: 1.0281\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=3 - Loss: 1.0222\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=3 - Loss: 1.0155\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=3 - Loss: 1.0083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=3 - Loss: 1.0010\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=3 - Loss: 0.9942\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=3 - Loss: 0.9869\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=3 - Loss: 0.9787\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=3 - Loss: 0.9699\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=3 - Loss: 0.9611\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=3 - Loss: 0.9526\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=3 - Loss: 0.9444\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=3 - Loss: 0.9362\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=3 - Loss: 0.9272\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=3 - Loss: 0.9170\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=3 - Loss: 0.9060\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=3 - Loss: 0.8945\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=3 - Loss: 0.8828\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=3 - Loss: 0.8757\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=3 - Loss: 0.8694\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=3 - Loss: 0.8477\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=3 - Loss: 0.8404\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=3 - Loss: 0.8221\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=3 - Loss: 0.8135\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=3 - Loss: 0.7977\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=3 - Loss: 0.7824\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=3 - Loss: 0.7697\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=3 - Loss: 0.7501\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=3 - Loss: 0.7376\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=3 - Loss: 0.7184\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=3 - Loss: 0.7019\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=3 - Loss: 0.6843\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=3 - Loss: 0.6644\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=3 - Loss: 0.6473\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=3 - Loss: 0.6280\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=3 - Loss: 0.6080\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=3 - Loss: 0.5928\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=3 - Loss: 0.5754\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=3 - Loss: 0.5624\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=3 - Loss: 0.5439\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=3 - Loss: 0.5242\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=3 - Loss: 0.5092\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=3 - Loss: 0.4908\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=3 - Loss: 0.4741\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=3 - Loss: 0.4567\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=3 - Loss: 0.4432\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=3 - Loss: 0.4233\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=3 - Loss: 0.4142\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=3 - Loss: 0.3963\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=3 - Loss: 0.3857\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=3 - Loss: 0.3713\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=3 - Loss: 0.3597\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=3 - Loss: 0.3408\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=3 - Loss: 0.3329\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=3 - Loss: 0.3166\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=3 - Loss: 0.3079\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=3 - Loss: 0.2938\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=3 - Loss: 0.2825\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=3 - Loss: 0.2722\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=3 - Loss: 0.2618\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=3 - Loss: 0.2501\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=3 - Loss: 0.2412\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=3 - Loss: 0.2315\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=3 - Loss: 0.2225\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=3 - Loss: 0.2136\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=3 - Loss: 0.2039\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=3 - Loss: 0.1974\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=3 - Loss: 0.1889\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=3 - Loss: 0.1829\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=3 - Loss: 0.1759\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=3 - Loss: 0.1705\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=3 - Loss: 0.1645\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=3 - Loss: 0.1563\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=3 - Loss: 0.1506\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=3 - Loss: 0.1444\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=1 - Loss: 1.0709\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=1 - Loss: 1.0670\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=1 - Loss: 1.0631\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=1 - Loss: 1.0593\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=1 - Loss: 1.0556\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=1 - Loss: 1.0519\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=1 - Loss: 1.0482\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=1 - Loss: 1.0445\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=1 - Loss: 1.0408\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=1 - Loss: 1.0370\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=1 - Loss: 1.0332\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=1 - Loss: 1.0293\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=1 - Loss: 1.0254\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=1 - Loss: 1.0213\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=1 - Loss: 1.0171\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=1 - Loss: 1.0128\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=1 - Loss: 1.0083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=1 - Loss: 1.0036\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=1 - Loss: 0.9987\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=1 - Loss: 0.9935\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=1 - Loss: 0.9878\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=1 - Loss: 0.9816\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=1 - Loss: 0.9748\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=1 - Loss: 0.9672\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=1 - Loss: 0.9589\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=1 - Loss: 0.9498\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=1 - Loss: 0.9396\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=1 - Loss: 0.9282\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=1 - Loss: 0.9171\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=1 - Loss: 0.9054\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=1 - Loss: 0.8925\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=1 - Loss: 0.8788\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=1 - Loss: 0.8638\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=1 - Loss: 0.8474\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=1 - Loss: 0.8326\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=1 - Loss: 0.8158\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=1 - Loss: 0.7995\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=1 - Loss: 0.7842\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=1 - Loss: 0.7693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=1 - Loss: 0.7550\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=1 - Loss: 0.7413\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=1 - Loss: 0.7264\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=1 - Loss: 0.7087\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=1 - Loss: 0.6988\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=1 - Loss: 0.6870\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=1 - Loss: 0.6687\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=1 - Loss: 0.6580\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=1 - Loss: 0.6375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=1 - Loss: 0.6238\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=1 - Loss: 0.6062\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=1 - Loss: 0.5946\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=1 - Loss: 0.5750\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=1 - Loss: 0.5620\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=1 - Loss: 0.5441\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=1 - Loss: 0.5316\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=1 - Loss: 0.5136\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=1 - Loss: 0.4995\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=1 - Loss: 0.4823\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=1 - Loss: 0.4675\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=1 - Loss: 0.4533\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=1 - Loss: 0.4425\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=1 - Loss: 0.4391\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=1 - Loss: 0.4247\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=1 - Loss: 0.4025\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=1 - Loss: 0.4023\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=1 - Loss: 0.3872\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=1 - Loss: 0.3740\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=1 - Loss: 0.3619\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=1 - Loss: 0.3448\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=1 - Loss: 0.3366\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=1 - Loss: 0.3237\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=1 - Loss: 0.3157\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=1 - Loss: 0.3017\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=1 - Loss: 0.2954\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=1 - Loss: 0.2799\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=1 - Loss: 0.2771\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=1 - Loss: 0.2624\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=1 - Loss: 0.2565\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=1 - Loss: 0.2449\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=1 - Loss: 0.2365\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=1 - Loss: 0.2289\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=1 - Loss: 0.2188\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=1 - Loss: 0.2130\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=1 - Loss: 0.2034\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=1 - Loss: 0.1973\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=1 - Loss: 0.1892\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=1 - Loss: 0.1831\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=1 - Loss: 0.1753\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=1 - Loss: 0.1684\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=1 - Loss: 0.1605\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=1 - Loss: 0.1541\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=1 - Loss: 0.1474\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=1 - Loss: 0.1419\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=1 - Loss: 0.1363\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=1 - Loss: 0.1328\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=1 - Loss: 0.1256\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=1 - Loss: 0.1204\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=1 - Loss: 0.1123\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=1 - Loss: 0.1071\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=1 - Loss: 0.1037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=2 - Loss: 1.0651\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=2 - Loss: 1.0623\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=2 - Loss: 1.0596\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=2 - Loss: 1.0570\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=2 - Loss: 1.0545\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=2 - Loss: 1.0520\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=2 - Loss: 1.0496\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=2 - Loss: 1.0471\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=2 - Loss: 1.0445\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=2 - Loss: 1.0416\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=2 - Loss: 1.0382\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=2 - Loss: 1.0343\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=2 - Loss: 1.0296\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=2 - Loss: 1.0242\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=2 - Loss: 1.0178\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=2 - Loss: 1.0102\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=2 - Loss: 1.0013\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=2 - Loss: 0.9910\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=2 - Loss: 0.9795\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=2 - Loss: 0.9679\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=2 - Loss: 0.9575\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=2 - Loss: 0.9476\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=2 - Loss: 0.9357\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=2 - Loss: 0.9229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=2 - Loss: 0.9114\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=2 - Loss: 0.8988\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=2 - Loss: 0.8851\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=2 - Loss: 0.8709\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=2 - Loss: 0.8578\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=2 - Loss: 0.8437\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=2 - Loss: 0.8283\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=2 - Loss: 0.8129\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=2 - Loss: 0.7953\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=2 - Loss: 0.7761\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=2 - Loss: 0.7601\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=2 - Loss: 0.7353\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=2 - Loss: 0.7171\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=2 - Loss: 0.6954\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=2 - Loss: 0.6741\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=2 - Loss: 0.6600\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=2 - Loss: 0.6474\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=2 - Loss: 0.6352\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=2 - Loss: 0.5994\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=2 - Loss: 0.6149\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=2 - Loss: 0.5736\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=2 - Loss: 0.5785\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=2 - Loss: 0.5453\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=2 - Loss: 0.5173\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=2 - Loss: 0.5132\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=2 - Loss: 0.4775\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=2 - Loss: 0.4589\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=2 - Loss: 0.4473\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=2 - Loss: 0.4209\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=2 - Loss: 0.3998\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=2 - Loss: 0.3887\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=2 - Loss: 0.3645\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=2 - Loss: 0.3469\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=2 - Loss: 0.3365\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=2 - Loss: 0.3111\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=2 - Loss: 0.2957\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=2 - Loss: 0.2848\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=2 - Loss: 0.2642\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=2 - Loss: 0.2548\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=2 - Loss: 0.2487\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=2 - Loss: 0.2185\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=2 - Loss: 0.2141\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=2 - Loss: 0.2219\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=2 - Loss: 0.1829\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=2 - Loss: 0.1864\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=2 - Loss: 0.1779\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=2 - Loss: 0.1606\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=2 - Loss: 0.1472\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=2 - Loss: 0.1384\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=2 - Loss: 0.1271\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=2 - Loss: 0.1223\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=2 - Loss: 0.1084\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=2 - Loss: 0.1024\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=2 - Loss: 0.0919\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=2 - Loss: 0.0858\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=2 - Loss: 0.0807\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=2 - Loss: 0.0708\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=2 - Loss: 0.0681\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=2 - Loss: 0.0614\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=2 - Loss: 0.0569\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=2 - Loss: 0.0515\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=2 - Loss: 0.0471\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=2 - Loss: 0.0437\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=2 - Loss: 0.0382\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=2 - Loss: 0.0365\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=2 - Loss: 0.0323\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=2 - Loss: 0.0288\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=2 - Loss: 0.0277\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=2 - Loss: 0.0240\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=2 - Loss: 0.0219\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=2 - Loss: 0.0197\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=2 - Loss: 0.0184\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=2 - Loss: 0.0164\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=2 - Loss: 0.0143\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=2 - Loss: 0.0135\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=2 - Loss: 0.0118\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=3 - Loss: 1.0688\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=3 - Loss: 1.0661\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=3 - Loss: 1.0636\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=3 - Loss: 1.0614\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=3 - Loss: 1.0593\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=3 - Loss: 1.0575\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=3 - Loss: 1.0561\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=3 - Loss: 1.0553\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=3 - Loss: 1.0544\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=3 - Loss: 1.0526\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=3 - Loss: 1.0503\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=3 - Loss: 1.0477\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=3 - Loss: 1.0446\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=3 - Loss: 1.0405\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=3 - Loss: 1.0351\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=3 - Loss: 1.0279\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=3 - Loss: 1.0186\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=3 - Loss: 1.0089\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=3 - Loss: 1.0027\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=3 - Loss: 0.9933\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=3 - Loss: 0.9812\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=3 - Loss: 0.9702\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=3 - Loss: 0.9596\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=3 - Loss: 0.9489\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=3 - Loss: 0.9336\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=3 - Loss: 0.9168\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=3 - Loss: 0.8975\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=3 - Loss: 0.8840\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=3 - Loss: 0.8741\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=3 - Loss: 0.8436\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=3 - Loss: 0.8404\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=3 - Loss: 0.8085\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=3 - Loss: 0.8013\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=3 - Loss: 0.7716\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=3 - Loss: 0.7616\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=3 - Loss: 0.7321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=3 - Loss: 0.7145\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=3 - Loss: 0.6910\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=3 - Loss: 0.6656\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=3 - Loss: 0.6485\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=3 - Loss: 0.6282\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=3 - Loss: 0.6210\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=3 - Loss: 0.5791\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=3 - Loss: 0.5623\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=3 - Loss: 0.5389\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=3 - Loss: 0.5122\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=3 - Loss: 0.4909\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=3 - Loss: 0.4649\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=3 - Loss: 0.4411\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=3 - Loss: 0.4214\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=3 - Loss: 0.3916\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=3 - Loss: 0.3743\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=3 - Loss: 0.3519\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=3 - Loss: 0.3324\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=3 - Loss: 0.3037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=3 - Loss: 0.2905\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=3 - Loss: 0.2693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=3 - Loss: 0.2576\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=3 - Loss: 0.2310\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=3 - Loss: 0.2154\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=3 - Loss: 0.1994\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=3 - Loss: 0.1853\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=3 - Loss: 0.1681\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=3 - Loss: 0.1594\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=3 - Loss: 0.1531\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=3 - Loss: 0.1321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=3 - Loss: 0.1216\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=3 - Loss: 0.1131\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=3 - Loss: 0.1014\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=3 - Loss: 0.0917\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=3 - Loss: 0.0847\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=3 - Loss: 0.0756\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=3 - Loss: 0.0697\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=3 - Loss: 0.0624\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=3 - Loss: 0.0563\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=3 - Loss: 0.0522\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=3 - Loss: 0.0460\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=3 - Loss: 0.0425\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=3 - Loss: 0.0386\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=3 - Loss: 0.0338\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=3 - Loss: 0.0317\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=3 - Loss: 0.0272\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=3 - Loss: 0.0245\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=3 - Loss: 0.0219\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=3 - Loss: 0.0203\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=3 - Loss: 0.0177\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=3 - Loss: 0.0156\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=3 - Loss: 0.0143\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=3 - Loss: 0.0124\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=3 - Loss: 0.0111\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=3 - Loss: 0.0098\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=3 - Loss: 0.0089\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=3 - Loss: 0.0078\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=3 - Loss: 0.0069\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=3 - Loss: 0.0058\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=3 - Loss: 0.0056\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=3 - Loss: 0.0046\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=3 - Loss: 0.0042\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=3 - Loss: 0.0037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=3 - Loss: 0.0032\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=1 - Loss: 1.0669\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=1 - Loss: 1.0611\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=1 - Loss: 1.0554\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=1 - Loss: 1.0498\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=1 - Loss: 1.0443\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=1 - Loss: 1.0387\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=1 - Loss: 1.0330\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=1 - Loss: 1.0272\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=1 - Loss: 1.0212\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=1 - Loss: 1.0149\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=1 - Loss: 1.0083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=1 - Loss: 1.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=1 - Loss: 0.9928\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=1 - Loss: 0.9832\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=1 - Loss: 0.9721\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=1 - Loss: 0.9595\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=1 - Loss: 0.9439\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=1 - Loss: 0.9435\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=1 - Loss: 0.9260\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=1 - Loss: 0.9243\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=1 - Loss: 0.9175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=1 - Loss: 0.9084\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=1 - Loss: 0.8978\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=1 - Loss: 0.8850\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=1 - Loss: 0.8693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=1 - Loss: 0.8549\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=1 - Loss: 0.8408\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=1 - Loss: 0.8249\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=1 - Loss: 0.8082\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=1 - Loss: 0.7948\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=1 - Loss: 0.7798\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=1 - Loss: 0.7652\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=1 - Loss: 0.7509\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=1 - Loss: 0.7329\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=1 - Loss: 0.7201\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=1 - Loss: 0.7056\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=1 - Loss: 0.6862\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=1 - Loss: 0.6728\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=1 - Loss: 0.6478\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=1 - Loss: 0.6283\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=1 - Loss: 0.6161\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=1 - Loss: 0.5947\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=1 - Loss: 0.5948\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=1 - Loss: 0.5540\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=1 - Loss: 0.5594\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=1 - Loss: 0.5568\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=1 - Loss: 0.5430\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=1 - Loss: 0.5045\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=1 - Loss: 0.5037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=1 - Loss: 0.4928\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=1 - Loss: 0.4721\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=1 - Loss: 0.4518\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=1 - Loss: 0.4600\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=1 - Loss: 0.4297\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=1 - Loss: 0.4099\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=1 - Loss: 0.4233\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=1 - Loss: 0.3902\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=1 - Loss: 0.3765\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=1 - Loss: 0.3799\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=1 - Loss: 0.3505\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=1 - Loss: 0.3388\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=1 - Loss: 0.3228\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=1 - Loss: 0.3200\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=1 - Loss: 0.2980\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=1 - Loss: 0.2867\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=1 - Loss: 0.2825\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=1 - Loss: 0.2641\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=1 - Loss: 0.2520\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=1 - Loss: 0.2414\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=1 - Loss: 0.2307\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=1 - Loss: 0.2199\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=1 - Loss: 0.2080\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=1 - Loss: 0.1979\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=1 - Loss: 0.1909\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=1 - Loss: 0.1785\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=1 - Loss: 0.1665\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=1 - Loss: 0.1589\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=1 - Loss: 0.1499\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=1 - Loss: 0.1412\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=1 - Loss: 0.1330\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=1 - Loss: 0.1238\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=1 - Loss: 0.1166\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=1 - Loss: 0.1112\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=1 - Loss: 0.1065\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=1 - Loss: 0.1081\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=1 - Loss: 0.1012\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=1 - Loss: 0.0939\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=1 - Loss: 0.0788\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=1 - Loss: 0.0822\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=1 - Loss: 0.0765\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=1 - Loss: 0.0647\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=1 - Loss: 0.0690\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=1 - Loss: 0.0572\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=1 - Loss: 0.0556\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=1 - Loss: 0.0498\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=1 - Loss: 0.0460\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=1 - Loss: 0.0442\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=1 - Loss: 0.0377\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=1 - Loss: 0.0388\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=1 - Loss: 0.0327\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=2 - Loss: 1.0707\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=2 - Loss: 1.0649\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=2 - Loss: 1.0596\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=2 - Loss: 1.0545\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=2 - Loss: 1.0494\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=2 - Loss: 1.0445\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=2 - Loss: 1.0404\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=2 - Loss: 1.0351\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=2 - Loss: 1.0273\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=2 - Loss: 1.0180\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=2 - Loss: 1.0071\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=2 - Loss: 0.9935\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=2 - Loss: 0.9784\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=2 - Loss: 0.9684\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=2 - Loss: 0.9501\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=2 - Loss: 0.9378\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=2 - Loss: 0.9238\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=2 - Loss: 0.9135\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=2 - Loss: 0.8986\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=2 - Loss: 0.8785\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=2 - Loss: 0.8674\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=2 - Loss: 0.8543\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=2 - Loss: 0.8275\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=2 - Loss: 0.8141\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=2 - Loss: 0.7863\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=2 - Loss: 0.7704\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=2 - Loss: 0.7546\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=2 - Loss: 0.7415\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=2 - Loss: 0.7329\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=2 - Loss: 0.6992\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=2 - Loss: 0.6782\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=2 - Loss: 0.6630\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=2 - Loss: 0.6301\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=2 - Loss: 0.6084\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=2 - Loss: 0.5933\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=2 - Loss: 0.5629\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=2 - Loss: 0.5264\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=2 - Loss: 0.5170\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=2 - Loss: 0.4903\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=2 - Loss: 0.4593\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=2 - Loss: 0.4291\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=2 - Loss: 0.4062\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=2 - Loss: 0.3895\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=2 - Loss: 0.3679\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=2 - Loss: 0.3411\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=2 - Loss: 0.3082\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=2 - Loss: 0.3080\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=2 - Loss: 0.2749\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=2 - Loss: 0.2483\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=2 - Loss: 0.2264\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=2 - Loss: 0.2024\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=2 - Loss: 0.1917\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=2 - Loss: 0.1637\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=2 - Loss: 0.1533\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=2 - Loss: 0.1310\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=2 - Loss: 0.1172\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=2 - Loss: 0.1035\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=2 - Loss: 0.0876\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=2 - Loss: 0.0779\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=2 - Loss: 0.0700\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=2 - Loss: 0.0572\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=2 - Loss: 0.0511\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=2 - Loss: 0.0464\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=2 - Loss: 0.0391\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=2 - Loss: 0.0342\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=2 - Loss: 0.0276\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=2 - Loss: 0.0257\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=2 - Loss: 0.0216\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=2 - Loss: 0.0175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=2 - Loss: 0.0166\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=2 - Loss: 0.0129\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=2 - Loss: 0.0124\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=2 - Loss: 0.0100\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=2 - Loss: 0.0086\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=2 - Loss: 0.0076\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=2 - Loss: 0.0068\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=2 - Loss: 0.0056\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=2 - Loss: 0.0053\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=2 - Loss: 0.0044\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=2 - Loss: 0.0044\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=2 - Loss: 0.0035\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=2 - Loss: 0.0033\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=2 - Loss: 0.0029\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=2 - Loss: 0.0025\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=2 - Loss: 0.0022\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=2 - Loss: 0.0021\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=2 - Loss: 0.0017\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=2 - Loss: 0.0016\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=2 - Loss: 0.0015\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=2 - Loss: 0.0014\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=2 - Loss: 0.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=2 - Loss: 0.0010\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=2 - Loss: 0.0010\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=2 - Loss: 0.0008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=2 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=2 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=2 - Loss: 0.0006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=2 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=2 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=2 - Loss: 0.0004\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=3 - Loss: 1.0693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=3 - Loss: 1.0644\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=3 - Loss: 1.0603\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=3 - Loss: 1.0572\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=3 - Loss: 1.0569\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=3 - Loss: 1.0546\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=3 - Loss: 1.0517\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=3 - Loss: 1.0487\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=3 - Loss: 1.0445\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=3 - Loss: 1.0381\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=3 - Loss: 1.0280\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=3 - Loss: 1.0125\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=3 - Loss: 0.9943\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=3 - Loss: 0.9778\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=3 - Loss: 0.9748\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=3 - Loss: 0.9703\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=3 - Loss: 0.9416\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=3 - Loss: 0.9385\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=3 - Loss: 0.9275\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=3 - Loss: 0.9155\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=3 - Loss: 0.9020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=3 - Loss: 0.8840\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=3 - Loss: 0.8625\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=3 - Loss: 0.8405\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=3 - Loss: 0.8169\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=3 - Loss: 0.7972\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=3 - Loss: 0.7739\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=3 - Loss: 0.7499\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=3 - Loss: 0.7227\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=3 - Loss: 0.6996\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=3 - Loss: 0.6980\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=3 - Loss: 0.6972\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=3 - Loss: 0.6643\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=3 - Loss: 0.6259\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=3 - Loss: 0.6098\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=3 - Loss: 0.5850\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=3 - Loss: 0.5525\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=3 - Loss: 0.5280\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=3 - Loss: 0.5041\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=3 - Loss: 0.4708\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=3 - Loss: 0.4390\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=3 - Loss: 0.4219\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=3 - Loss: 0.3872\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=3 - Loss: 0.3568\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=3 - Loss: 0.3309\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=3 - Loss: 0.2993\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=3 - Loss: 0.2707\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=3 - Loss: 0.2473\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=3 - Loss: 0.2172\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=3 - Loss: 0.1961\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=3 - Loss: 0.1710\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=3 - Loss: 0.1534\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=3 - Loss: 0.1349\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=3 - Loss: 0.1203\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=3 - Loss: 0.0999\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=3 - Loss: 0.0861\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=3 - Loss: 0.0766\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=3 - Loss: 0.0637\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=3 - Loss: 0.0528\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=3 - Loss: 0.0452\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=3 - Loss: 0.0390\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=3 - Loss: 0.0325\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=3 - Loss: 0.0265\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=3 - Loss: 0.0225\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=3 - Loss: 0.0194\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=3 - Loss: 0.0157\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=3 - Loss: 0.0138\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=3 - Loss: 0.0121\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=3 - Loss: 0.0095\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=3 - Loss: 0.0087\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=3 - Loss: 0.0072\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=3 - Loss: 0.0059\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=3 - Loss: 0.0052\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=3 - Loss: 0.0043\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=3 - Loss: 0.0037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=3 - Loss: 0.0035\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=3 - Loss: 0.0031\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=3 - Loss: 0.0028\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=3 - Loss: 0.0025\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=3 - Loss: 0.0024\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=3 - Loss: 0.0021\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=3 - Loss: 0.0019\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=3 - Loss: 0.0018\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=3 - Loss: 0.0016\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=3 - Loss: 0.0014\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=3 - Loss: 0.0013\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=3 - Loss: 0.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=3 - Loss: 0.0010\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=3 - Loss: 0.0009\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=3 - Loss: 0.0008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=3 - Loss: 0.0008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=3 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=3 - Loss: 0.0006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=3 - Loss: 0.0006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=3 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=3 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=3 - Loss: 0.0004\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=3 - Loss: 0.0004\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=3 - Loss: 0.0003\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=3 - Loss: 0.0003\n",
      "\n",
      "Best Model Found!\n",
      "Hidden Size: 256\n",
      "Number of Layers: 3\n",
      "Best Training Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameter search loop\n",
    "hidden_sizes = [64, 128, 256]  # Example hidden sizes to test\n",
    "num_layers_list = [1, 2, 3]  # Number of LSTM layers to test\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "num_epochs = 100  # Number of epochs for training (increase this to iterate more)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Dummy input and target data (to be replaced with actual data)\n",
    "input_data = torch.randn(64, 30, 9)  # Batch size 64, 30 time steps, 9 features\n",
    "target_data = torch.randn(64, 16)    # Batch size 64, 16 outputs\n",
    "\n",
    "# Loop through different hyperparameter combinations\n",
    "for hidden_size in hidden_sizes:\n",
    "    for num_layers in num_layers_list:\n",
    "        \n",
    "        # Create the model with current hyperparameters\n",
    "        model = SequencePredictionModel(input_size=9, hidden_size=hidden_size, output_size=16, num_layers=num_layers)\n",
    "        \n",
    "        # Define the optimizer and loss function\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "        \n",
    "        # Train the model for multiple epochs\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):  # Iterate over multiple epochs\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get the model output for the training data\n",
    "            outputs = model(input_data)\n",
    "            \n",
    "            # Compute the loss for training data\n",
    "            loss = criterion(outputs, target_data)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss for the current epoch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], hidden_size={hidden_size}, num_layers={num_layers} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # After all epochs, check if this model is the best so far\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model = model\n",
    "            best_hyperparameters = {'hidden_size': hidden_size, 'num_layers': num_layers}\n",
    "\n",
    "# Print the best model and its hyperparameters based on training loss\n",
    "print(\"\\nBest Model Found!\")\n",
    "print(f\"Hidden Size: {best_hyperparameters['hidden_size']}\")\n",
    "print(f\"Number of Layers: {best_hyperparameters['num_layers']}\")\n",
    "print(f\"Best Training Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best loss found is 0.0003 and that is with 3 layers and a hidden size of 256. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM (Validation): torch.Size([41530, 30, 9])\n",
      "Target shape for validation: torch.Size([41530, 1])\n",
      "Input shape for LSTM: torch.Size([41530, 30, 9])\n",
      "Model output shape: torch.Size([41530, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/betaknight/gpt_module/gpt_animatronic/gpt_testing/gpt_venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([41530, 1])) that is different to the input size (torch.Size([41530, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5353\n"
     ]
    }
   ],
   "source": [
    "# Ensure val_data is at least 2D\n",
    "if val_data.dim() == 1:\n",
    "    val_data = val_data.unsqueeze(-1)  # Convert (num_samples,) → (num_samples, 1)\n",
    "\n",
    "# Create sequences for validation\n",
    "x_val = torch.stack([val_data[i:i+block_size] for i in range(len(val_data) - block_size)])  # (batch_size, block_size, num_features)\n",
    "\n",
    "# Fix target extraction: Extract last 16 values per sample\n",
    "y_val = torch.stack([val_data[i+block_size, -16:] for i in range(len(val_data) - block_size)])  # (batch_size, 16)\n",
    "\n",
    "# Ensure input shape matches LSTM expectations\n",
    "x_val = x_val.expand(-1, -1, 9).float()  # Expand feature dimension to match model\n",
    "\n",
    "# Ensure target is float\n",
    "y_val = y_val.float()\n",
    "\n",
    "# Debugging: Check shapes\n",
    "print(f\"Input shape for LSTM (Validation): {x_val.shape}\")  # (batch_size, 30, 9)\n",
    "print(f\"Target shape for validation: {y_val.shape}\")  # (batch_size, 16)\n",
    "\n",
    "# Forward pass through the model\n",
    "best_model.eval()\n",
    "outputs_val = best_model(x_val)\n",
    "\n",
    "# Debugging: Check output shape\n",
    "print(f\"Model output shape: {outputs_val.shape}\")  # Should be (batch_size, 16)\n",
    "\n",
    "# Compute validation loss\n",
    "validation_loss = nn.MSELoss()(outputs_val, y_val)\n",
    "\n",
    "# Print the validation loss\n",
    "print(f\"Validation Loss: {validation_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on our first batch of trained data this is what our model predicted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\\nimport torch\\n\\n# Load the GPT-2 small model and tokenizer\\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Move the model to the correct device (MPS for Mac)\\ndevice = \"mps\"  # for MPS on Mac\\nmodel.to(device)\\n\\n# Hyperparameters\\nlearning_rate = 3e-4\\nmax_iters = 1000\\neval_iters = 250\\nbatch_size = 4\\n\\n# Create a PyTorch optimizer\\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\\n\\n# Learning rate scheduler (StepLR)\\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\\n\\n# Training loop\\nfor iter in range(max_iters):\\n    if iter % eval_iters == 0:\\n        losses = estimate_loss()  # Define your custom function to compute loss\\n        print(f\"step: {iter}, train loss: {losses[\\'train\\']:.3f}, val loss: {losses[\\'val\\']:.3f}\")\\n\\n    # Sample a batch of data (assumed to provide text data)\\n    xb, yb = get_batch(\\'train\\')  # Ensure this returns text data\\n\\n    # Tokenize input and label text\\n    inputs = tokenizer(xb, return_tensors=\\'pt\\', padding=True, truncation=True, max_length=512).to(device)\\n    labels = tokenizer(yb, return_tensors=\\'pt\\', padding=True, truncation=True, max_length=512).to(device)\\n\\n    # Prepare attention mask\\n    attention_mask = inputs[\\'attention_mask\\']\\n\\n    # Forward pass through GPT-2 model with `use_cache=False` to disable past_key_values\\n    outputs = model(input_ids=inputs[\\'input_ids\\'], labels=labels[\\'input_ids\\'], attention_mask=attention_mask, use_cache=False)\\n\\n    # Get the loss value from the model\\'s output\\n    loss = outputs.loss\\n\\n    # Backpropagation and optimization\\n    optimizer.zero_grad(set_to_none=True)\\n    loss.backward()\\n    optimizer.step()\\n\\n    # Update the learning rate after each step\\n    scheduler.step()\\n\\n    # Print the loss value at regular intervals\\n    if iter % 100 == 0:\\n        print(f\"Iter {iter} - Loss: {loss.item()}\")\\n\\n# Final model loss\\nprint(f\"Final loss: {loss.item()}\")\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the GPT-2 small model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Move the model to the correct device (MPS for Mac)\n",
    "device = \"mps\"  # for MPS on Mac\n",
    "model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 3e-4\n",
    "max_iters = 1000\n",
    "eval_iters = 250\n",
    "batch_size = 4\n",
    "\n",
    "# Create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler (StepLR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\n",
    "\n",
    "# Training loop\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()  # Define your custom function to compute loss\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # Sample a batch of data (assumed to provide text data)\n",
    "    xb, yb = get_batch('train')  # Ensure this returns text data\n",
    "\n",
    "    # Tokenize input and label text\n",
    "    inputs = tokenizer(xb, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    labels = tokenizer(yb, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    # Prepare attention mask\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Forward pass through GPT-2 model with `use_cache=False` to disable past_key_values\n",
    "    outputs = model(input_ids=inputs['input_ids'], labels=labels['input_ids'], attention_mask=attention_mask, use_cache=False)\n",
    "\n",
    "    # Get the loss value from the model's output\n",
    "    loss = outputs.loss\n",
    "\n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update the learning rate after each step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the loss value at regular intervals\n",
    "    if iter % 100 == 0:\n",
    "        print(f\"Iter {iter} - Loss: {loss.item()}\")\n",
    "\n",
    "# Final model loss\n",
    "print(f\"Final loss: {loss.item()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SequencePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SequencePredictionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass (this may already be defined)\n",
    "        pass\n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        generated = context.float()  # Convert context to float32\n",
    "\n",
    "        # Debugging print: Checking the shape of the context tensor at the start\n",
    "        print(f\"Initial context shape: {generated.shape}\")\n",
    "        \n",
    "        # Ensure that context has 3 dimensions, (batch_size, sequence_length, input_size)\n",
    "        if generated.dim() == 2:  # If context is 2D, add a dummy feature dimension\n",
    "            generated = generated.unsqueeze(-1)  # (batch_size, sequence_length, 1)\n",
    "            print(f\"After unsqueeze: {generated.shape}\")  # Debugging\n",
    "\n",
    "        # Now, check if the context has the right number of features (9), and expand if necessary\n",
    "        if generated.size(-1) != 9:\n",
    "            print(f\"Before expand: {generated.shape}\")  # Debugging\n",
    "            generated = generated.expand(-1, -1, 9)  # Expand to match 9 features\n",
    "            print(f\"After expand: {generated.shape}\")  # Debugging\n",
    "\n",
    "        # Now we are ready to generate new tokens\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Forward pass through the LSTM\n",
    "            lstm_out, _ = self.lstm(generated)\n",
    "            \n",
    "            # Get the output from the last time step (predicted token)\n",
    "            output = self.fc(lstm_out[:, -1, :])  # Pass through the fully connected layer\n",
    "            next_token = output.argmax(dim=-1)  # Choose the token with the highest probability\n",
    "            \n",
    "            # Append the generated token to the context for the next step\n",
    "            next_token_expanded = next_token.unsqueeze(0).unsqueeze(-1).float()  # Convert to float32 and add necessary dimensions\n",
    "            generated = torch.cat((generated, next_token_expanded.expand(-1, -1, 9)), dim=1)  # Add the new token to context\n",
    "\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequencePredictionModel' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m best_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Generate the output from the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m generated_output \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(context, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Flatten the output and ensure it's a list of indices by using argmax\u001b[39;00m\n\u001b[1;32m     11\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m generated_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/gpt_module/gpt_animatronic/gpt_testing/gpt_venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequencePredictionModel' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "# Ensure both model and input tensor are on the same device\n",
    "context = torch.randn((1, 1, 9), dtype=torch.float32, device=device)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "best_model.to(device)\n",
    "\n",
    "# Generate the output from the model\n",
    "generated_output = best_model.generate(context, max_new_tokens=500)\n",
    "\n",
    "# Flatten the output and ensure it's a list of indices by using argmax\n",
    "generated_tokens = generated_output[0].flatten().argmax(dim=-1).tolist()\n",
    "\n",
    "# Make sure generated_tokens is a list\n",
    "if not isinstance(generated_tokens, list):\n",
    "    generated_tokens = [generated_tokens]\n",
    "\n",
    "# Decode the generated tokens\n",
    "generated_chars = decode(generated_tokens)\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know it still is unreadable, but if you notice, the letters are making more and more sense. And, you might actually catch a couple words here and there if you run it a couple of times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
