{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practicing with Matrices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be testing and trying out different methods that can be used to train and enhance our model to be able to effectively learn from a large file. First we will start off with small books, and then move on from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c3/gd7dympn2rq3xs5m82fgbzz80000gn/T/ipykernel_42937/923978391.py:6: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = 'mps' if torch.has_mps else 'cpu'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Check for MPS support (for Metal GPU acceleration on macOS)\n",
    "device = 'mps' if torch.has_mps else 'cpu'\n",
    "print(device)\n",
    "\n",
    "block_size = 16  # increase block size to allow more context\n",
    "batch_size = 32  # increase batch size for better gradient estimates\n",
    "max_iters = 5000  # increase max iterations for more training time\n",
    "learning_rate = 5e-4  # try a slightly higher learning rate\n",
    "eval_iters = 100  # evaluate more frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This just shows that you have successfully installed Metal on your device. As long as it shows mps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '&', '(', ')', ',', '-', '.', '0', '1', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "with open('wonderful_wizard_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! 73 is the amount of each individual character shown in this whole book! Later on we will convert each one into a token and then further down we will embedden them into matrices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([72, 34, 48, 45,  1, 37, 55, 54, 44, 45, 58, 46, 61, 52,  1, 37, 49, 66,\n",
      "        41, 58, 44,  1, 55, 46,  1, 29, 66,  0,  0, 42, 65,  1, 26,  8,  1, 20,\n",
      "        58, 41, 54, 51,  1, 16, 41, 61, 53,  0,  0,  0, 34, 48, 49, 59,  1, 42,\n",
      "        55, 55, 51,  1, 49, 59,  1, 44, 45, 44, 49, 43, 41, 60, 45, 44,  1, 60,\n",
      "        55,  1, 53, 65,  1, 47, 55, 55, 44,  1, 46, 58, 49, 45, 54, 44,  1,  3,\n",
      "         1, 43, 55, 53, 58, 41, 44, 45,  0, 27])\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how now each letter, space, symbol, indent, etc. now has its own classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([64, 30])\n",
      "tensor([[0.8056, 0.7639, 0.8750,  ..., 0.5972, 0.7639, 0.8472],\n",
      "        [0.6667, 0.6250, 0.7361,  ..., 0.7639, 0.8056, 0.0139],\n",
      "        [0.0139, 0.8333, 0.7639,  ..., 0.5833, 0.8056, 0.5694],\n",
      "        ...,\n",
      "        [0.0139, 0.3194, 0.6389,  ..., 0.3194, 0.0139, 0.8750],\n",
      "        [0.7222, 0.0139, 0.8194,  ..., 0.7500, 0.8194, 0.1111],\n",
      "        [0.6806, 0.7222, 0.7222,  ..., 0.0139, 0.7639, 0.6389]],\n",
      "       device='mps:0')\n",
      "torch.Size([64, 30])\n",
      "targets:\n",
      "tensor([[0.7639, 0.8750, 0.1111,  ..., 0.7639, 0.8472, 0.8056],\n",
      "        [0.6250, 0.7361, 0.0139,  ..., 0.8056, 0.0139, 0.5694],\n",
      "        [0.8333, 0.7639, 0.0139,  ..., 0.8056, 0.5694, 0.6806],\n",
      "        ...,\n",
      "        [0.3194, 0.6389, 0.0139,  ..., 0.0139, 0.8750, 0.6806],\n",
      "        [0.0139, 0.8194, 0.8333,  ..., 0.8194, 0.1111, 0.0139],\n",
      "        [0.7222, 0.7222, 0.0139,  ..., 0.7639, 0.6389, 0.0139]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "block_size = 30  # Sequence length (number of tokens per sequence)\n",
    "batch_size = 64  # Number of sequences per batch\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# Compute min/max from training data only\n",
    "min_val, max_val = train_data.min(), train_data.max()\n",
    "\n",
    "# Normalize train and validation data (using train's min/max for consistency)\n",
    "train_data = (train_data - min_val) / (max_val - min_val)\n",
    "val_data = (val_data - min_val) / (max_val - min_val)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # Select starting points of sequences\n",
    "\n",
    "    # Create sequences and targets\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])  # shape: (batch_size, block_size)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  # shape: (batch_size, block_size)\n",
    "\n",
    "    # Moving data to device (GPU if available)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# Get a batch\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x.shape)  # Should be (batch_size, block_size)\n",
    "print(x)\n",
    "print(y.shape)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now split. 80 percent train and 20% validation. the get_batch function takes either the **'train'** or **'val'** sets and gets random bunches from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about model not being defined yet, we first need to class the Birgramlanguange model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass BigramLanguageModel(nn.Module):\\n    def __init__(self, vocab_size):\\n        super().__init__()\\n        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\\n        \\n    def forward(self, index, targets=None):\\n        logits = self.token_embedding_table(index)\\n        \\n        if targets is None:\\n            loss = None\\n        else:\\n            B, T, C = logits.shape\\n            logits = logits.view(B * T, C)\\n            targets = targets.view(B * T)\\n            loss = F.cross_entropy(logits, targets)\\n        \\n        return logits, loss\\n    \\n    def generate(self, index, max_new_tokens):\\n        # index is (B, T) array of indices in the current context\\n        for _ in range(max_new_tokens):\\n            # get the predictions\\n            logits, loss = self.forward(index)\\n            # focus only on the last time step\\n            logits = logits[:, -1, :]  # becomes (B, C)\\n            # apply softmax to get probabilities\\n            probs = F.softmax(logits, dim=-1)  # (B, C)\\n            # sample from the distribution\\n            index_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\\n            # append sampled index to the running sequence\\n            index = torch.cat((index, index_next), dim=1)  # (B, T+1)\\n        return index\\n\\nmodel = BigramLanguageModel(vocab_size)\\nm = model.to(device)\\n\\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\\ngenerated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\\nprint(generated_chars)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1)  # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Loss: 0.9758\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SequencePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(SequencePredictionModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with correct input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to output the prediction\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure the input is in float32 format\n",
    "        x = x.float()\n",
    "\n",
    "        # If the input is 2D (batch_size, sequence_length), assume 1 feature per time step\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(-1)  # Add a feature dimension, making it (batch_size, sequence_length, 1)\n",
    "\n",
    "        # Ensure the input has the correct shape for the LSTM: (batch_size, sequence_length, 9)\n",
    "        if x.size(-1) == 1:  # Check if the input has 1 feature per timestep\n",
    "            x = x.expand(-1, -1, 9)  # Expand to 9 features per timestep\n",
    "\n",
    "        # Check input shape for debugging\n",
    "        print(f\"Input shape for LSTM: {x.shape}\")\n",
    "\n",
    "        # Initialize hidden state with zeros (set to float32)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float32).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float32).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Only take the output from the last time step\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer output\n",
    "        out = self.fc(last_time_step_out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Example of model usage:\n",
    "input_size = 9  # Number of features per time step (adjust as per data)\n",
    "hidden_size = 128  # Hidden size of the LSTM layer\n",
    "output_size = 16  # Output size (adjust based on target)\n",
    "\n",
    "# Creating the model\n",
    "model = SequencePredictionModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Dummy input with 3D shape (batch_size=64, sequence_length=30, input_size=9)\n",
    "x = torch.randn(64, 30, 9)  # 64 sequences, 30 timesteps per sequence\n",
    "\n",
    "# Dummy target (y) with 2D shape (batch_size=64, output_size=16)\n",
    "y = torch.randn(64, 16)  # Target with 16 values per sequence\n",
    "\n",
    "# Forward pass\n",
    "output = model(x)\n",
    "\n",
    "# Compute the loss\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss (for regression tasks)\n",
    "loss = criterion(output, y)\n",
    "\n",
    "# Backward pass and optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=1 - Loss: 0.9594\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=1 - Loss: 0.9563\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=1 - Loss: 0.9533\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=1 - Loss: 0.9504\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=1 - Loss: 0.9475\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=1 - Loss: 0.9446\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=1 - Loss: 0.9418\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=1 - Loss: 0.9390\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=1 - Loss: 0.9362\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=1 - Loss: 0.9334\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=1 - Loss: 0.9307\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=1 - Loss: 0.9279\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=1 - Loss: 0.9251\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=1 - Loss: 0.9223\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=1 - Loss: 0.9195\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=1 - Loss: 0.9167\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=1 - Loss: 0.9138\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=1 - Loss: 0.9109\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=1 - Loss: 0.9080\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=1 - Loss: 0.9050\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=1 - Loss: 0.9020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=1 - Loss: 0.8989\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=1 - Loss: 0.8957\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=1 - Loss: 0.8925\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=1 - Loss: 0.8893\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=1 - Loss: 0.8860\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=1 - Loss: 0.8826\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=1 - Loss: 0.8792\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=1 - Loss: 0.8757\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=1 - Loss: 0.8722\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=1 - Loss: 0.8687\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=1 - Loss: 0.8651\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=1 - Loss: 0.8615\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=1 - Loss: 0.8577\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=1 - Loss: 0.8539\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=1 - Loss: 0.8499\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=1 - Loss: 0.8457\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=1 - Loss: 0.8414\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=1 - Loss: 0.8371\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=1 - Loss: 0.8327\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=1 - Loss: 0.8282\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=1 - Loss: 0.8236\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=1 - Loss: 0.8189\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=1 - Loss: 0.8141\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=1 - Loss: 0.8091\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=1 - Loss: 0.8038\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=1 - Loss: 0.7982\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=1 - Loss: 0.7924\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=1 - Loss: 0.7864\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=1 - Loss: 0.7801\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=1 - Loss: 0.7736\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=1 - Loss: 0.7672\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=1 - Loss: 0.7607\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=1 - Loss: 0.7544\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=1 - Loss: 0.7480\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=1 - Loss: 0.7414\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=1 - Loss: 0.7343\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=1 - Loss: 0.7268\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=1 - Loss: 0.7188\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=1 - Loss: 0.7106\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=1 - Loss: 0.7021\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=1 - Loss: 0.6931\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=1 - Loss: 0.6837\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=1 - Loss: 0.6741\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=1 - Loss: 0.6645\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=1 - Loss: 0.6550\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=1 - Loss: 0.6458\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=1 - Loss: 0.6380\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=1 - Loss: 0.6290\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=1 - Loss: 0.6188\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=1 - Loss: 0.6104\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=1 - Loss: 0.6019\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=1 - Loss: 0.5919\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=1 - Loss: 0.5832\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=1 - Loss: 0.5742\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=1 - Loss: 0.5645\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=1 - Loss: 0.5552\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=1 - Loss: 0.5462\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=1 - Loss: 0.5365\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=1 - Loss: 0.5267\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=1 - Loss: 0.5175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=1 - Loss: 0.5088\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=1 - Loss: 0.5002\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=1 - Loss: 0.4902\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=1 - Loss: 0.4801\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=1 - Loss: 0.4712\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=1 - Loss: 0.4632\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=1 - Loss: 0.4543\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=1 - Loss: 0.4446\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=1 - Loss: 0.4360\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=1 - Loss: 0.4280\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=1 - Loss: 0.4197\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=1 - Loss: 0.4111\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=1 - Loss: 0.4020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=1 - Loss: 0.3941\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=1 - Loss: 0.3867\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=1 - Loss: 0.3791\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=1 - Loss: 0.3719\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=1 - Loss: 0.3635\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=1 - Loss: 0.3549\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=2 - Loss: 0.9451\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=2 - Loss: 0.9430\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=2 - Loss: 0.9410\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=2 - Loss: 0.9391\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=2 - Loss: 0.9373\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=2 - Loss: 0.9355\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=2 - Loss: 0.9338\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=2 - Loss: 0.9321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=2 - Loss: 0.9304\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=2 - Loss: 0.9287\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=2 - Loss: 0.9270\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=2 - Loss: 0.9253\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=2 - Loss: 0.9236\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=2 - Loss: 0.9219\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=2 - Loss: 0.9202\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=2 - Loss: 0.9185\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=2 - Loss: 0.9167\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=2 - Loss: 0.9147\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=2 - Loss: 0.9127\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=2 - Loss: 0.9105\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=2 - Loss: 0.9081\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=2 - Loss: 0.9054\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=2 - Loss: 0.9025\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=2 - Loss: 0.8993\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=2 - Loss: 0.8958\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=2 - Loss: 0.8920\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=2 - Loss: 0.8879\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=2 - Loss: 0.8834\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=2 - Loss: 0.8784\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=2 - Loss: 0.8729\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=2 - Loss: 0.8669\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=2 - Loss: 0.8605\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=2 - Loss: 0.8537\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=2 - Loss: 0.8468\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=2 - Loss: 0.8395\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=2 - Loss: 0.8321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=2 - Loss: 0.8248\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=2 - Loss: 0.8175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=2 - Loss: 0.8101\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=2 - Loss: 0.8022\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=2 - Loss: 0.7935\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=2 - Loss: 0.7842\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=2 - Loss: 0.7740\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=2 - Loss: 0.7634\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=2 - Loss: 0.7523\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=2 - Loss: 0.7409\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=2 - Loss: 0.7290\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=2 - Loss: 0.7169\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=2 - Loss: 0.7045\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=2 - Loss: 0.6912\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=2 - Loss: 0.6780\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=2 - Loss: 0.6685\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=2 - Loss: 0.6554\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=2 - Loss: 0.6398\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=2 - Loss: 0.6299\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=2 - Loss: 0.6126\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=2 - Loss: 0.6030\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=2 - Loss: 0.5873\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=2 - Loss: 0.5739\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=2 - Loss: 0.5614\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=2 - Loss: 0.5472\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=2 - Loss: 0.5339\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=2 - Loss: 0.5213\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=2 - Loss: 0.5061\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=2 - Loss: 0.4940\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=2 - Loss: 0.4802\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=2 - Loss: 0.4679\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=2 - Loss: 0.4549\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=2 - Loss: 0.4423\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=2 - Loss: 0.4305\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=2 - Loss: 0.4174\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=2 - Loss: 0.4060\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=2 - Loss: 0.3952\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=2 - Loss: 0.3839\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=2 - Loss: 0.3738\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=2 - Loss: 0.3595\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=2 - Loss: 0.3476\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=2 - Loss: 0.3404\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=2 - Loss: 0.3274\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=2 - Loss: 0.3159\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=2 - Loss: 0.3083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=2 - Loss: 0.2960\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=2 - Loss: 0.2874\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=2 - Loss: 0.2762\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=2 - Loss: 0.2678\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=2 - Loss: 0.2601\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=2 - Loss: 0.2495\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=2 - Loss: 0.2433\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=2 - Loss: 0.2331\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=2 - Loss: 0.2268\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=2 - Loss: 0.2210\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=2 - Loss: 0.2159\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=2 - Loss: 0.2065\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=2 - Loss: 0.1996\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=2 - Loss: 0.1950\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=2 - Loss: 0.1914\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=2 - Loss: 0.1821\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=2 - Loss: 0.1754\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=2 - Loss: 0.1687\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=2 - Loss: 0.1646\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=64, num_layers=3 - Loss: 0.9490\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=64, num_layers=3 - Loss: 0.9469\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=64, num_layers=3 - Loss: 0.9449\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=64, num_layers=3 - Loss: 0.9430\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=64, num_layers=3 - Loss: 0.9411\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=64, num_layers=3 - Loss: 0.9393\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=64, num_layers=3 - Loss: 0.9376\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=64, num_layers=3 - Loss: 0.9360\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=64, num_layers=3 - Loss: 0.9345\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=64, num_layers=3 - Loss: 0.9333\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=64, num_layers=3 - Loss: 0.9325\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=64, num_layers=3 - Loss: 0.9322\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=64, num_layers=3 - Loss: 0.9322\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=64, num_layers=3 - Loss: 0.9320\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=64, num_layers=3 - Loss: 0.9314\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=64, num_layers=3 - Loss: 0.9305\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=64, num_layers=3 - Loss: 0.9296\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=64, num_layers=3 - Loss: 0.9289\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=64, num_layers=3 - Loss: 0.9282\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=64, num_layers=3 - Loss: 0.9275\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=64, num_layers=3 - Loss: 0.9267\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=64, num_layers=3 - Loss: 0.9258\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=64, num_layers=3 - Loss: 0.9246\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=64, num_layers=3 - Loss: 0.9231\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=64, num_layers=3 - Loss: 0.9213\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=64, num_layers=3 - Loss: 0.9191\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=64, num_layers=3 - Loss: 0.9164\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=64, num_layers=3 - Loss: 0.9133\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=64, num_layers=3 - Loss: 0.9099\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=64, num_layers=3 - Loss: 0.9063\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=64, num_layers=3 - Loss: 0.9029\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=64, num_layers=3 - Loss: 0.8996\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=64, num_layers=3 - Loss: 0.8954\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=64, num_layers=3 - Loss: 0.8901\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=64, num_layers=3 - Loss: 0.8841\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=64, num_layers=3 - Loss: 0.8781\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=64, num_layers=3 - Loss: 0.8723\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=64, num_layers=3 - Loss: 0.8665\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=64, num_layers=3 - Loss: 0.8603\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=64, num_layers=3 - Loss: 0.8535\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=64, num_layers=3 - Loss: 0.8461\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=64, num_layers=3 - Loss: 0.8389\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=64, num_layers=3 - Loss: 0.8310\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=64, num_layers=3 - Loss: 0.8215\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=64, num_layers=3 - Loss: 0.8139\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=64, num_layers=3 - Loss: 0.8049\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=64, num_layers=3 - Loss: 0.7965\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=64, num_layers=3 - Loss: 0.7869\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=64, num_layers=3 - Loss: 0.7755\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=64, num_layers=3 - Loss: 0.7658\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=64, num_layers=3 - Loss: 0.7523\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=64, num_layers=3 - Loss: 0.7415\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=64, num_layers=3 - Loss: 0.7340\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=64, num_layers=3 - Loss: 0.7176\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=64, num_layers=3 - Loss: 0.7074\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=64, num_layers=3 - Loss: 0.6904\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=64, num_layers=3 - Loss: 0.6836\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=64, num_layers=3 - Loss: 0.6693\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=64, num_layers=3 - Loss: 0.6586\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=64, num_layers=3 - Loss: 0.6434\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=64, num_layers=3 - Loss: 0.6339\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=64, num_layers=3 - Loss: 0.6181\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=64, num_layers=3 - Loss: 0.6063\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=64, num_layers=3 - Loss: 0.5914\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=64, num_layers=3 - Loss: 0.5784\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=64, num_layers=3 - Loss: 0.5652\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=64, num_layers=3 - Loss: 0.5543\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=64, num_layers=3 - Loss: 0.5427\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=64, num_layers=3 - Loss: 0.5284\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=64, num_layers=3 - Loss: 0.5175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=64, num_layers=3 - Loss: 0.5040\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=64, num_layers=3 - Loss: 0.4959\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=64, num_layers=3 - Loss: 0.4819\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=64, num_layers=3 - Loss: 0.4727\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=64, num_layers=3 - Loss: 0.4608\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=64, num_layers=3 - Loss: 0.4501\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=64, num_layers=3 - Loss: 0.4390\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=64, num_layers=3 - Loss: 0.4295\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=64, num_layers=3 - Loss: 0.4186\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=64, num_layers=3 - Loss: 0.4069\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=64, num_layers=3 - Loss: 0.3966\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=64, num_layers=3 - Loss: 0.3872\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=64, num_layers=3 - Loss: 0.3779\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=64, num_layers=3 - Loss: 0.3706\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=64, num_layers=3 - Loss: 0.3624\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=64, num_layers=3 - Loss: 0.3531\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=64, num_layers=3 - Loss: 0.3438\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=64, num_layers=3 - Loss: 0.3368\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=64, num_layers=3 - Loss: 0.3289\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=64, num_layers=3 - Loss: 0.3186\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=64, num_layers=3 - Loss: 0.3097\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=64, num_layers=3 - Loss: 0.3030\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=64, num_layers=3 - Loss: 0.2951\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=64, num_layers=3 - Loss: 0.2859\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=64, num_layers=3 - Loss: 0.2795\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=64, num_layers=3 - Loss: 0.2717\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=64, num_layers=3 - Loss: 0.2663\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=64, num_layers=3 - Loss: 0.2580\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=64, num_layers=3 - Loss: 0.2529\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=64, num_layers=3 - Loss: 0.2453\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=1 - Loss: 0.9533\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=1 - Loss: 0.9486\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=1 - Loss: 0.9442\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=1 - Loss: 0.9398\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=1 - Loss: 0.9355\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=1 - Loss: 0.9312\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=1 - Loss: 0.9269\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=1 - Loss: 0.9227\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=1 - Loss: 0.9184\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=1 - Loss: 0.9140\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=1 - Loss: 0.9096\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=1 - Loss: 0.9051\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=1 - Loss: 0.9006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=1 - Loss: 0.8961\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=1 - Loss: 0.8918\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=1 - Loss: 0.8877\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=1 - Loss: 0.8839\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=1 - Loss: 0.8801\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=1 - Loss: 0.8755\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=1 - Loss: 0.8705\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=1 - Loss: 0.8652\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=1 - Loss: 0.8600\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=1 - Loss: 0.8547\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=1 - Loss: 0.8490\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=1 - Loss: 0.8428\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=1 - Loss: 0.8360\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=1 - Loss: 0.8289\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=1 - Loss: 0.8223\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=1 - Loss: 0.8136\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=1 - Loss: 0.8070\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=1 - Loss: 0.7989\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=1 - Loss: 0.7900\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=1 - Loss: 0.7809\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=1 - Loss: 0.7714\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=1 - Loss: 0.7597\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=1 - Loss: 0.7503\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=1 - Loss: 0.7375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=1 - Loss: 0.7265\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=1 - Loss: 0.7147\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=1 - Loss: 0.7045\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=1 - Loss: 0.6923\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=1 - Loss: 0.6824\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=1 - Loss: 0.6691\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=1 - Loss: 0.6578\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=1 - Loss: 0.6450\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=1 - Loss: 0.6323\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=1 - Loss: 0.6201\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=1 - Loss: 0.6107\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=1 - Loss: 0.6032\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=1 - Loss: 0.5865\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=1 - Loss: 0.5751\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=1 - Loss: 0.5621\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=1 - Loss: 0.5520\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=1 - Loss: 0.5382\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=1 - Loss: 0.5234\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=1 - Loss: 0.5136\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=1 - Loss: 0.5011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=1 - Loss: 0.4931\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=1 - Loss: 0.4769\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=1 - Loss: 0.4697\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=1 - Loss: 0.4573\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=1 - Loss: 0.4479\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=1 - Loss: 0.4375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=1 - Loss: 0.4278\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=1 - Loss: 0.4195\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=1 - Loss: 0.4101\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=1 - Loss: 0.3989\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=1 - Loss: 0.3915\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=1 - Loss: 0.3844\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=1 - Loss: 0.3709\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=1 - Loss: 0.3668\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=1 - Loss: 0.3537\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=1 - Loss: 0.3462\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=1 - Loss: 0.3373\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=1 - Loss: 0.3271\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=1 - Loss: 0.3204\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=1 - Loss: 0.3110\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=1 - Loss: 0.3044\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=1 - Loss: 0.2954\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=1 - Loss: 0.2887\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=1 - Loss: 0.2806\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=1 - Loss: 0.2725\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=1 - Loss: 0.2656\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=1 - Loss: 0.2580\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=1 - Loss: 0.2510\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=1 - Loss: 0.2438\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=1 - Loss: 0.2369\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=1 - Loss: 0.2302\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=1 - Loss: 0.2237\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=1 - Loss: 0.2169\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=1 - Loss: 0.2106\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=1 - Loss: 0.2045\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=1 - Loss: 0.1973\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=1 - Loss: 0.1916\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=1 - Loss: 0.1859\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=1 - Loss: 0.1790\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=1 - Loss: 0.1733\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=1 - Loss: 0.1681\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=1 - Loss: 0.1663\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=1 - Loss: 0.1736\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=2 - Loss: 0.9490\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=2 - Loss: 0.9449\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=2 - Loss: 0.9411\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=2 - Loss: 0.9375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=2 - Loss: 0.9339\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=2 - Loss: 0.9305\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=2 - Loss: 0.9271\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=2 - Loss: 0.9241\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=2 - Loss: 0.9217\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=2 - Loss: 0.9201\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=2 - Loss: 0.9181\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=2 - Loss: 0.9152\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=2 - Loss: 0.9117\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=2 - Loss: 0.9082\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=2 - Loss: 0.9047\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=2 - Loss: 0.9009\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=2 - Loss: 0.8966\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=2 - Loss: 0.8914\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=2 - Loss: 0.8853\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=2 - Loss: 0.8783\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=2 - Loss: 0.8704\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=2 - Loss: 0.8621\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=2 - Loss: 0.8529\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=2 - Loss: 0.8424\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=2 - Loss: 0.8331\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=2 - Loss: 0.8232\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=2 - Loss: 0.8114\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=2 - Loss: 0.8001\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=2 - Loss: 0.7869\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=2 - Loss: 0.7716\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=2 - Loss: 0.7573\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=2 - Loss: 0.7635\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=2 - Loss: 0.7344\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=2 - Loss: 0.7322\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=2 - Loss: 0.7188\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=2 - Loss: 0.7027\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=2 - Loss: 0.6949\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=2 - Loss: 0.6717\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=2 - Loss: 0.6640\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=2 - Loss: 0.6469\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=2 - Loss: 0.6364\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=2 - Loss: 0.6214\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=2 - Loss: 0.6058\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=2 - Loss: 0.5935\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=2 - Loss: 0.5772\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=2 - Loss: 0.5648\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=2 - Loss: 0.5510\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=2 - Loss: 0.5357\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=2 - Loss: 0.5203\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=2 - Loss: 0.5067\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=2 - Loss: 0.4862\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=2 - Loss: 0.4726\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=2 - Loss: 0.4557\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=2 - Loss: 0.4397\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=2 - Loss: 0.4225\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=2 - Loss: 0.4101\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=2 - Loss: 0.4005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=2 - Loss: 0.3881\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=2 - Loss: 0.3743\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=2 - Loss: 0.3530\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=2 - Loss: 0.3430\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=2 - Loss: 0.3222\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=2 - Loss: 0.3150\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=2 - Loss: 0.2909\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=2 - Loss: 0.2891\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=2 - Loss: 0.2725\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=2 - Loss: 0.2575\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=2 - Loss: 0.2483\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=2 - Loss: 0.2357\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=2 - Loss: 0.2229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=2 - Loss: 0.2092\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=2 - Loss: 0.1989\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=2 - Loss: 0.1877\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=2 - Loss: 0.1758\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=2 - Loss: 0.1669\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=2 - Loss: 0.1535\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=2 - Loss: 0.1457\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=2 - Loss: 0.1347\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=2 - Loss: 0.1267\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=2 - Loss: 0.1172\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=2 - Loss: 0.1083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=2 - Loss: 0.1013\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=2 - Loss: 0.0923\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=2 - Loss: 0.0868\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=2 - Loss: 0.0785\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=2 - Loss: 0.0733\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=2 - Loss: 0.0663\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=2 - Loss: 0.0619\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=2 - Loss: 0.0556\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=2 - Loss: 0.0520\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=2 - Loss: 0.0464\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=2 - Loss: 0.0430\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=2 - Loss: 0.0384\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=2 - Loss: 0.0351\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=2 - Loss: 0.0311\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=2 - Loss: 0.0285\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=2 - Loss: 0.0256\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=2 - Loss: 0.0237\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=2 - Loss: 0.0209\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=2 - Loss: 0.0184\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=128, num_layers=3 - Loss: 0.9489\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=128, num_layers=3 - Loss: 0.9457\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=128, num_layers=3 - Loss: 0.9426\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=128, num_layers=3 - Loss: 0.9397\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=128, num_layers=3 - Loss: 0.9369\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=128, num_layers=3 - Loss: 0.9342\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=128, num_layers=3 - Loss: 0.9321\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=128, num_layers=3 - Loss: 0.9314\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=128, num_layers=3 - Loss: 0.9312\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=128, num_layers=3 - Loss: 0.9297\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=128, num_layers=3 - Loss: 0.9279\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=128, num_layers=3 - Loss: 0.9265\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=128, num_layers=3 - Loss: 0.9251\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=128, num_layers=3 - Loss: 0.9234\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=128, num_layers=3 - Loss: 0.9209\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=128, num_layers=3 - Loss: 0.9174\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=128, num_layers=3 - Loss: 0.9126\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=128, num_layers=3 - Loss: 0.9064\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=128, num_layers=3 - Loss: 0.8993\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=128, num_layers=3 - Loss: 0.8904\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=128, num_layers=3 - Loss: 0.8822\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=128, num_layers=3 - Loss: 0.8757\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=128, num_layers=3 - Loss: 0.8699\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=128, num_layers=3 - Loss: 0.8615\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=128, num_layers=3 - Loss: 0.8544\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=128, num_layers=3 - Loss: 0.8464\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=128, num_layers=3 - Loss: 0.8374\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=128, num_layers=3 - Loss: 0.8288\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=128, num_layers=3 - Loss: 0.8199\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=128, num_layers=3 - Loss: 0.8095\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=128, num_layers=3 - Loss: 0.7970\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=128, num_layers=3 - Loss: 0.7882\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=128, num_layers=3 - Loss: 0.7757\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=128, num_layers=3 - Loss: 0.7638\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=128, num_layers=3 - Loss: 0.7558\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=128, num_layers=3 - Loss: 0.7546\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=128, num_layers=3 - Loss: 0.7305\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=128, num_layers=3 - Loss: 0.7335\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=128, num_layers=3 - Loss: 0.7100\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=128, num_layers=3 - Loss: 0.7142\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=128, num_layers=3 - Loss: 0.6840\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=128, num_layers=3 - Loss: 0.6787\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=128, num_layers=3 - Loss: 0.6658\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=128, num_layers=3 - Loss: 0.6439\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=128, num_layers=3 - Loss: 0.6407\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=128, num_layers=3 - Loss: 0.6198\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=128, num_layers=3 - Loss: 0.6061\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=128, num_layers=3 - Loss: 0.5926\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=128, num_layers=3 - Loss: 0.5787\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=128, num_layers=3 - Loss: 0.5634\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=128, num_layers=3 - Loss: 0.5459\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=128, num_layers=3 - Loss: 0.5302\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=128, num_layers=3 - Loss: 0.5121\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=128, num_layers=3 - Loss: 0.4963\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=128, num_layers=3 - Loss: 0.4811\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=128, num_layers=3 - Loss: 0.4636\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=128, num_layers=3 - Loss: 0.4512\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=128, num_layers=3 - Loss: 0.4310\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=128, num_layers=3 - Loss: 0.4212\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=128, num_layers=3 - Loss: 0.4026\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=128, num_layers=3 - Loss: 0.3864\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=128, num_layers=3 - Loss: 0.3720\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=128, num_layers=3 - Loss: 0.3568\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=128, num_layers=3 - Loss: 0.3384\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=128, num_layers=3 - Loss: 0.3266\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=128, num_layers=3 - Loss: 0.3090\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=128, num_layers=3 - Loss: 0.2974\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=128, num_layers=3 - Loss: 0.2818\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=128, num_layers=3 - Loss: 0.2668\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=128, num_layers=3 - Loss: 0.2564\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=128, num_layers=3 - Loss: 0.2426\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=128, num_layers=3 - Loss: 0.2316\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=128, num_layers=3 - Loss: 0.2229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=128, num_layers=3 - Loss: 0.2109\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=128, num_layers=3 - Loss: 0.2037\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=128, num_layers=3 - Loss: 0.1894\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=128, num_layers=3 - Loss: 0.1770\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=128, num_layers=3 - Loss: 0.1673\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=128, num_layers=3 - Loss: 0.1563\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=128, num_layers=3 - Loss: 0.1491\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=128, num_layers=3 - Loss: 0.1371\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=128, num_layers=3 - Loss: 0.1303\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=128, num_layers=3 - Loss: 0.1209\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=128, num_layers=3 - Loss: 0.1146\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=128, num_layers=3 - Loss: 0.1057\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=128, num_layers=3 - Loss: 0.0993\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=128, num_layers=3 - Loss: 0.0913\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=128, num_layers=3 - Loss: 0.0866\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=128, num_layers=3 - Loss: 0.0793\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=128, num_layers=3 - Loss: 0.0758\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=128, num_layers=3 - Loss: 0.0715\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=128, num_layers=3 - Loss: 0.0698\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=128, num_layers=3 - Loss: 0.0735\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=128, num_layers=3 - Loss: 0.0629\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=128, num_layers=3 - Loss: 0.0549\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=128, num_layers=3 - Loss: 0.0533\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=128, num_layers=3 - Loss: 0.0450\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=128, num_layers=3 - Loss: 0.0445\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=128, num_layers=3 - Loss: 0.0367\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=128, num_layers=3 - Loss: 0.0362\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=1 - Loss: 0.9496\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=1 - Loss: 0.9432\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=1 - Loss: 0.9370\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=1 - Loss: 0.9308\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=1 - Loss: 0.9247\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=1 - Loss: 0.9185\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=1 - Loss: 0.9121\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=1 - Loss: 0.9056\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=1 - Loss: 0.8990\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=1 - Loss: 0.8925\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=1 - Loss: 0.8869\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=1 - Loss: 0.8821\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=1 - Loss: 0.8753\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=1 - Loss: 0.8675\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=1 - Loss: 0.8601\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=1 - Loss: 0.8528\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=1 - Loss: 0.8447\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=1 - Loss: 0.8353\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=1 - Loss: 0.8241\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=1 - Loss: 0.8152\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=1 - Loss: 0.8092\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=1 - Loss: 0.7940\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=1 - Loss: 0.7841\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=1 - Loss: 0.7717\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=1 - Loss: 0.7597\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=1 - Loss: 0.7460\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=1 - Loss: 0.7354\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=1 - Loss: 0.7178\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=1 - Loss: 0.7237\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=1 - Loss: 0.7145\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=1 - Loss: 0.7281\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=1 - Loss: 0.7275\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=1 - Loss: 0.7184\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=1 - Loss: 0.7029\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=1 - Loss: 0.6823\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=1 - Loss: 0.6677\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=1 - Loss: 0.6534\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=1 - Loss: 0.6431\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=1 - Loss: 0.6362\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=1 - Loss: 0.6198\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=1 - Loss: 0.6125\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=1 - Loss: 0.5904\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=1 - Loss: 0.5805\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=1 - Loss: 0.5670\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=1 - Loss: 0.5572\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=1 - Loss: 0.5403\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=1 - Loss: 0.5300\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=1 - Loss: 0.5135\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=1 - Loss: 0.5031\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=1 - Loss: 0.4827\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=1 - Loss: 0.4676\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=1 - Loss: 0.4537\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=1 - Loss: 0.4386\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=1 - Loss: 0.4205\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=1 - Loss: 0.4070\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=1 - Loss: 0.3920\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=1 - Loss: 0.3849\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=1 - Loss: 0.3899\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=1 - Loss: 0.3570\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=1 - Loss: 0.3518\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=1 - Loss: 0.3315\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=1 - Loss: 0.3208\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=1 - Loss: 0.3042\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=1 - Loss: 0.2867\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=1 - Loss: 0.2815\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=1 - Loss: 0.2618\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=1 - Loss: 0.2492\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=1 - Loss: 0.2399\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=1 - Loss: 0.2253\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=1 - Loss: 0.2161\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=1 - Loss: 0.2044\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=1 - Loss: 0.1935\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=1 - Loss: 0.1816\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=1 - Loss: 0.1751\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=1 - Loss: 0.1620\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=1 - Loss: 0.1543\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=1 - Loss: 0.1448\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=1 - Loss: 0.1353\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=1 - Loss: 0.1284\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=1 - Loss: 0.1202\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=1 - Loss: 0.1118\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=1 - Loss: 0.1051\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=1 - Loss: 0.0986\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=1 - Loss: 0.0913\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=1 - Loss: 0.0851\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=1 - Loss: 0.0785\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=1 - Loss: 0.0731\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=1 - Loss: 0.0671\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=1 - Loss: 0.0628\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=1 - Loss: 0.0580\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=1 - Loss: 0.0541\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=1 - Loss: 0.0518\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=1 - Loss: 0.0483\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=1 - Loss: 0.0460\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=1 - Loss: 0.0377\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=1 - Loss: 0.0348\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=1 - Loss: 0.0360\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=1 - Loss: 0.0306\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=1 - Loss: 0.0250\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=1 - Loss: 0.0229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=2 - Loss: 0.9434\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=2 - Loss: 0.9380\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=2 - Loss: 0.9332\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=2 - Loss: 0.9287\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=2 - Loss: 0.9246\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=2 - Loss: 0.9211\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=2 - Loss: 0.9180\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=2 - Loss: 0.9136\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=2 - Loss: 0.9079\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=2 - Loss: 0.9016\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=2 - Loss: 0.8944\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=2 - Loss: 0.8854\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=2 - Loss: 0.8740\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=2 - Loss: 0.8601\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=2 - Loss: 0.8461\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=2 - Loss: 0.8302\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=2 - Loss: 0.8143\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=2 - Loss: 0.8008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=2 - Loss: 0.7895\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=2 - Loss: 0.7705\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=2 - Loss: 0.7559\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=2 - Loss: 0.7437\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=2 - Loss: 0.7288\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=2 - Loss: 0.7111\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=2 - Loss: 0.7152\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=2 - Loss: 0.6821\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=2 - Loss: 0.6833\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=2 - Loss: 0.6608\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=2 - Loss: 0.6346\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=2 - Loss: 0.6307\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=2 - Loss: 0.6152\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=2 - Loss: 0.5939\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=2 - Loss: 0.5729\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=2 - Loss: 0.5542\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=2 - Loss: 0.5288\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=2 - Loss: 0.5030\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=2 - Loss: 0.4862\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=2 - Loss: 0.4606\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=2 - Loss: 0.4452\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=2 - Loss: 0.4144\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=2 - Loss: 0.3943\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=2 - Loss: 0.3762\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=2 - Loss: 0.3513\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=2 - Loss: 0.3299\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=2 - Loss: 0.3086\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=2 - Loss: 0.2891\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=2 - Loss: 0.2698\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=2 - Loss: 0.2494\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=2 - Loss: 0.2294\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=2 - Loss: 0.2139\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=2 - Loss: 0.2035\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=2 - Loss: 0.1828\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=2 - Loss: 0.1697\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=2 - Loss: 0.1519\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=2 - Loss: 0.1419\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=2 - Loss: 0.1220\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=2 - Loss: 0.1158\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=2 - Loss: 0.1127\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=2 - Loss: 0.0918\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=2 - Loss: 0.0908\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=2 - Loss: 0.0838\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=2 - Loss: 0.0712\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=2 - Loss: 0.0657\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=2 - Loss: 0.0549\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=2 - Loss: 0.0492\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=2 - Loss: 0.0450\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=2 - Loss: 0.0353\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=2 - Loss: 0.0335\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=2 - Loss: 0.0274\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=2 - Loss: 0.0229\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=2 - Loss: 0.0218\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=2 - Loss: 0.0167\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=2 - Loss: 0.0153\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=2 - Loss: 0.0125\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=2 - Loss: 0.0103\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=2 - Loss: 0.0096\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=2 - Loss: 0.0077\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=2 - Loss: 0.0070\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=2 - Loss: 0.0062\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=2 - Loss: 0.0049\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=2 - Loss: 0.0046\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=2 - Loss: 0.0043\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=2 - Loss: 0.0034\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=2 - Loss: 0.0031\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=2 - Loss: 0.0030\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=2 - Loss: 0.0024\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=2 - Loss: 0.0023\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=2 - Loss: 0.0021\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=2 - Loss: 0.0017\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=2 - Loss: 0.0016\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=2 - Loss: 0.0015\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=2 - Loss: 0.0012\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=2 - Loss: 0.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=2 - Loss: 0.0010\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=2 - Loss: 0.0009\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=2 - Loss: 0.0008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=2 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=2 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=2 - Loss: 0.0006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=2 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [1/100], hidden_size=256, num_layers=3 - Loss: 0.9448\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [2/100], hidden_size=256, num_layers=3 - Loss: 0.9402\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [3/100], hidden_size=256, num_layers=3 - Loss: 0.9363\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [4/100], hidden_size=256, num_layers=3 - Loss: 0.9328\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [5/100], hidden_size=256, num_layers=3 - Loss: 0.9309\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [6/100], hidden_size=256, num_layers=3 - Loss: 0.9302\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [7/100], hidden_size=256, num_layers=3 - Loss: 0.9275\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [8/100], hidden_size=256, num_layers=3 - Loss: 0.9252\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [9/100], hidden_size=256, num_layers=3 - Loss: 0.9224\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [10/100], hidden_size=256, num_layers=3 - Loss: 0.9183\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [11/100], hidden_size=256, num_layers=3 - Loss: 0.9120\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [12/100], hidden_size=256, num_layers=3 - Loss: 0.9026\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [13/100], hidden_size=256, num_layers=3 - Loss: 0.8901\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [14/100], hidden_size=256, num_layers=3 - Loss: 0.8819\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [15/100], hidden_size=256, num_layers=3 - Loss: 0.8690\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [16/100], hidden_size=256, num_layers=3 - Loss: 0.8548\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [17/100], hidden_size=256, num_layers=3 - Loss: 0.8455\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [18/100], hidden_size=256, num_layers=3 - Loss: 0.8346\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [19/100], hidden_size=256, num_layers=3 - Loss: 0.8228\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [20/100], hidden_size=256, num_layers=3 - Loss: 0.8093\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [21/100], hidden_size=256, num_layers=3 - Loss: 0.7928\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [22/100], hidden_size=256, num_layers=3 - Loss: 0.7798\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [23/100], hidden_size=256, num_layers=3 - Loss: 0.7612\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [24/100], hidden_size=256, num_layers=3 - Loss: 0.7412\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [25/100], hidden_size=256, num_layers=3 - Loss: 0.7226\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [26/100], hidden_size=256, num_layers=3 - Loss: 0.7232\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [27/100], hidden_size=256, num_layers=3 - Loss: 0.6960\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [28/100], hidden_size=256, num_layers=3 - Loss: 0.6789\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [29/100], hidden_size=256, num_layers=3 - Loss: 0.6510\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [30/100], hidden_size=256, num_layers=3 - Loss: 0.6429\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [31/100], hidden_size=256, num_layers=3 - Loss: 0.6276\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [32/100], hidden_size=256, num_layers=3 - Loss: 0.6063\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [33/100], hidden_size=256, num_layers=3 - Loss: 0.5798\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [34/100], hidden_size=256, num_layers=3 - Loss: 0.5630\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [35/100], hidden_size=256, num_layers=3 - Loss: 0.5367\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [36/100], hidden_size=256, num_layers=3 - Loss: 0.5098\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [37/100], hidden_size=256, num_layers=3 - Loss: 0.4921\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [38/100], hidden_size=256, num_layers=3 - Loss: 0.4606\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [39/100], hidden_size=256, num_layers=3 - Loss: 0.4440\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [40/100], hidden_size=256, num_layers=3 - Loss: 0.4146\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [41/100], hidden_size=256, num_layers=3 - Loss: 0.3849\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [42/100], hidden_size=256, num_layers=3 - Loss: 0.3644\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [43/100], hidden_size=256, num_layers=3 - Loss: 0.3375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [44/100], hidden_size=256, num_layers=3 - Loss: 0.3134\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [45/100], hidden_size=256, num_layers=3 - Loss: 0.2907\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [46/100], hidden_size=256, num_layers=3 - Loss: 0.2659\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [47/100], hidden_size=256, num_layers=3 - Loss: 0.2493\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [48/100], hidden_size=256, num_layers=3 - Loss: 0.2375\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [49/100], hidden_size=256, num_layers=3 - Loss: 0.2360\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [50/100], hidden_size=256, num_layers=3 - Loss: 0.1953\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [51/100], hidden_size=256, num_layers=3 - Loss: 0.1986\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [52/100], hidden_size=256, num_layers=3 - Loss: 0.1606\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [53/100], hidden_size=256, num_layers=3 - Loss: 0.1639\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [54/100], hidden_size=256, num_layers=3 - Loss: 0.1362\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [55/100], hidden_size=256, num_layers=3 - Loss: 0.1227\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [56/100], hidden_size=256, num_layers=3 - Loss: 0.1153\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [57/100], hidden_size=256, num_layers=3 - Loss: 0.0987\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [58/100], hidden_size=256, num_layers=3 - Loss: 0.0867\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [59/100], hidden_size=256, num_layers=3 - Loss: 0.0788\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [60/100], hidden_size=256, num_layers=3 - Loss: 0.0688\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [61/100], hidden_size=256, num_layers=3 - Loss: 0.0608\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [62/100], hidden_size=256, num_layers=3 - Loss: 0.0525\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [63/100], hidden_size=256, num_layers=3 - Loss: 0.0450\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [64/100], hidden_size=256, num_layers=3 - Loss: 0.0394\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [65/100], hidden_size=256, num_layers=3 - Loss: 0.0334\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [66/100], hidden_size=256, num_layers=3 - Loss: 0.0286\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [67/100], hidden_size=256, num_layers=3 - Loss: 0.0241\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [68/100], hidden_size=256, num_layers=3 - Loss: 0.0209\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [69/100], hidden_size=256, num_layers=3 - Loss: 0.0175\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [70/100], hidden_size=256, num_layers=3 - Loss: 0.0143\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [71/100], hidden_size=256, num_layers=3 - Loss: 0.0118\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [72/100], hidden_size=256, num_layers=3 - Loss: 0.0102\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [73/100], hidden_size=256, num_layers=3 - Loss: 0.0083\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [74/100], hidden_size=256, num_layers=3 - Loss: 0.0066\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [75/100], hidden_size=256, num_layers=3 - Loss: 0.0057\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [76/100], hidden_size=256, num_layers=3 - Loss: 0.0049\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [77/100], hidden_size=256, num_layers=3 - Loss: 0.0043\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [78/100], hidden_size=256, num_layers=3 - Loss: 0.0038\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [79/100], hidden_size=256, num_layers=3 - Loss: 0.0035\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [80/100], hidden_size=256, num_layers=3 - Loss: 0.0031\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [81/100], hidden_size=256, num_layers=3 - Loss: 0.0028\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [82/100], hidden_size=256, num_layers=3 - Loss: 0.0024\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [83/100], hidden_size=256, num_layers=3 - Loss: 0.0022\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [84/100], hidden_size=256, num_layers=3 - Loss: 0.0020\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [85/100], hidden_size=256, num_layers=3 - Loss: 0.0018\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [86/100], hidden_size=256, num_layers=3 - Loss: 0.0017\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [87/100], hidden_size=256, num_layers=3 - Loss: 0.0015\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [88/100], hidden_size=256, num_layers=3 - Loss: 0.0014\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [89/100], hidden_size=256, num_layers=3 - Loss: 0.0012\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [90/100], hidden_size=256, num_layers=3 - Loss: 0.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [91/100], hidden_size=256, num_layers=3 - Loss: 0.0011\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [92/100], hidden_size=256, num_layers=3 - Loss: 0.0009\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [93/100], hidden_size=256, num_layers=3 - Loss: 0.0008\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [94/100], hidden_size=256, num_layers=3 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [95/100], hidden_size=256, num_layers=3 - Loss: 0.0007\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [96/100], hidden_size=256, num_layers=3 - Loss: 0.0006\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [97/100], hidden_size=256, num_layers=3 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [98/100], hidden_size=256, num_layers=3 - Loss: 0.0005\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [99/100], hidden_size=256, num_layers=3 - Loss: 0.0004\n",
      "Input shape for LSTM: torch.Size([64, 30, 9])\n",
      "Epoch [100/100], hidden_size=256, num_layers=3 - Loss: 0.0004\n",
      "\n",
      "Best Model Found!\n",
      "Hidden Size: 256\n",
      "Number of Layers: 3\n",
      "Best Training Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameter search loop\n",
    "hidden_sizes = [64, 128, 256]  # Example hidden sizes to test\n",
    "num_layers_list = [1, 2, 3]  # Number of LSTM layers to test\n",
    "learning_rate = 0.001  # Learning rate for the optimizer\n",
    "num_epochs = 100  # Number of epochs for training (increase this to iterate more)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Dummy input and target data (to be replaced with actual data)\n",
    "input_data = torch.randn(64, 30, 9)  # Batch size 64, 30 time steps, 9 features\n",
    "target_data = torch.randn(64, 16)    # Batch size 64, 16 outputs\n",
    "\n",
    "# Loop through different hyperparameter combinations\n",
    "for hidden_size in hidden_sizes:\n",
    "    for num_layers in num_layers_list:\n",
    "        \n",
    "        # Create the model with current hyperparameters\n",
    "        model = SequencePredictionModel(input_size=9, hidden_size=hidden_size, output_size=16, num_layers=num_layers)\n",
    "        \n",
    "        # Define the optimizer and loss function\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "        \n",
    "        # Train the model for multiple epochs\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):  # Iterate over multiple epochs\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get the model output for the training data\n",
    "            outputs = model(input_data)\n",
    "            \n",
    "            # Compute the loss for training data\n",
    "            loss = criterion(outputs, target_data)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print loss for the current epoch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], hidden_size={hidden_size}, num_layers={num_layers} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # After all epochs, check if this model is the best so far\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model = model\n",
    "            best_hyperparameters = {'hidden_size': hidden_size, 'num_layers': num_layers}\n",
    "\n",
    "# Print the best model and its hyperparameters based on training loss\n",
    "print(\"\\nBest Model Found!\")\n",
    "print(f\"Hidden Size: {best_hyperparameters['hidden_size']}\")\n",
    "print(f\"Number of Layers: {best_hyperparameters['num_layers']}\")\n",
    "print(f\"Best Training Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best loss found is 0.0003 and that is with 3 layers and a hidden size of 256. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for LSTM (Validation): torch.Size([41530, 30, 9])\n",
      "Target shape for validation: torch.Size([41530, 1])\n",
      "Input shape for LSTM: torch.Size([41530, 30, 9])\n",
      "Model output shape: torch.Size([41530, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/betaknight/gpt_module/gpt_animatronic/gpt_testing/gpt_venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([41530, 1])) that is different to the input size (torch.Size([41530, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8678\n"
     ]
    }
   ],
   "source": [
    "# Ensure val_data is at least 2D\n",
    "if val_data.dim() == 1:\n",
    "    val_data = val_data.unsqueeze(-1)  # Convert (num_samples,) → (num_samples, 1)\n",
    "\n",
    "# Create sequences for validation\n",
    "x_val = torch.stack([val_data[i:i+block_size] for i in range(len(val_data) - block_size)])  # (batch_size, block_size, num_features)\n",
    "\n",
    "# Fix target extraction: Extract last 16 values per sample\n",
    "y_val = torch.stack([val_data[i+block_size, -16:] for i in range(len(val_data) - block_size)])  # (batch_size, 16)\n",
    "\n",
    "# Ensure input shape matches LSTM expectations\n",
    "x_val = x_val.expand(-1, -1, 9).float()  # Expand feature dimension to match model\n",
    "\n",
    "# Ensure target is float\n",
    "y_val = y_val.float()\n",
    "\n",
    "# Debugging: Check shapes\n",
    "print(f\"Input shape for LSTM (Validation): {x_val.shape}\")  # (batch_size, 30, 9)\n",
    "print(f\"Target shape for validation: {y_val.shape}\")  # (batch_size, 16)\n",
    "\n",
    "# Forward pass through the model\n",
    "best_model.eval()\n",
    "outputs_val = best_model(x_val)\n",
    "\n",
    "# Debugging: Check output shape\n",
    "print(f\"Model output shape: {outputs_val.shape}\")  # Should be (batch_size, 16)\n",
    "\n",
    "# Compute validation loss\n",
    "validation_loss = nn.MSELoss()(outputs_val, y_val)\n",
    "\n",
    "# Print the validation loss\n",
    "print(f\"Validation Loss: {validation_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on our first batch of trained data this is what our model predicted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\\nimport torch\\n\\n# Load the GPT-2 small model and tokenizer\\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Move the model to the correct device (MPS for Mac)\\ndevice = \"mps\"  # for MPS on Mac\\nmodel.to(device)\\n\\n# Hyperparameters\\nlearning_rate = 3e-4\\nmax_iters = 1000\\neval_iters = 250\\nbatch_size = 4\\n\\n# Create a PyTorch optimizer\\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\\n\\n# Learning rate scheduler (StepLR)\\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\\n\\n# Training loop\\nfor iter in range(max_iters):\\n    if iter % eval_iters == 0:\\n        losses = estimate_loss()  # Define your custom function to compute loss\\n        print(f\"step: {iter}, train loss: {losses[\\'train\\']:.3f}, val loss: {losses[\\'val\\']:.3f}\")\\n\\n    # Sample a batch of data (assumed to provide text data)\\n    xb, yb = get_batch(\\'train\\')  # Ensure this returns text data\\n\\n    # Tokenize input and label text\\n    inputs = tokenizer(xb, return_tensors=\\'pt\\', padding=True, truncation=True, max_length=512).to(device)\\n    labels = tokenizer(yb, return_tensors=\\'pt\\', padding=True, truncation=True, max_length=512).to(device)\\n\\n    # Prepare attention mask\\n    attention_mask = inputs[\\'attention_mask\\']\\n\\n    # Forward pass through GPT-2 model with `use_cache=False` to disable past_key_values\\n    outputs = model(input_ids=inputs[\\'input_ids\\'], labels=labels[\\'input_ids\\'], attention_mask=attention_mask, use_cache=False)\\n\\n    # Get the loss value from the model\\'s output\\n    loss = outputs.loss\\n\\n    # Backpropagation and optimization\\n    optimizer.zero_grad(set_to_none=True)\\n    loss.backward()\\n    optimizer.step()\\n\\n    # Update the learning rate after each step\\n    scheduler.step()\\n\\n    # Print the loss value at regular intervals\\n    if iter % 100 == 0:\\n        print(f\"Iter {iter} - Loss: {loss.item()}\")\\n\\n# Final model loss\\nprint(f\"Final loss: {loss.item()}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the GPT-2 small model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Move the model to the correct device (MPS for Mac)\n",
    "device = \"mps\"  # for MPS on Mac\n",
    "model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 3e-4\n",
    "max_iters = 1000\n",
    "eval_iters = 250\n",
    "batch_size = 4\n",
    "\n",
    "# Create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler (StepLR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\n",
    "\n",
    "# Training loop\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()  # Define your custom function to compute loss\n",
    "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # Sample a batch of data (assumed to provide text data)\n",
    "    xb, yb = get_batch('train')  # Ensure this returns text data\n",
    "\n",
    "    # Tokenize input and label text\n",
    "    inputs = tokenizer(xb, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    labels = tokenizer(yb, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    # Prepare attention mask\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Forward pass through GPT-2 model with `use_cache=False` to disable past_key_values\n",
    "    outputs = model(input_ids=inputs['input_ids'], labels=labels['input_ids'], attention_mask=attention_mask, use_cache=False)\n",
    "\n",
    "    # Get the loss value from the model's output\n",
    "    loss = outputs.loss\n",
    "\n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update the learning rate after each step\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print the loss value at regular intervals\n",
    "    if iter % 100 == 0:\n",
    "        print(f\"Iter {iter} - Loss: {loss.item()}\")\n",
    "\n",
    "# Final model loss\n",
    "print(f\"Final loss: {loss.item()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SequencePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SequencePredictionModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass (this may already be defined)\n",
    "        pass\n",
    "\n",
    "    def generate(self, context, max_new_tokens):\n",
    "        generated = context.float()  # Convert context to float32\n",
    "\n",
    "        # Debugging print: Checking the shape of the context tensor at the start\n",
    "        print(f\"Initial context shape: {generated.shape}\")\n",
    "        \n",
    "        # Ensure that context has 3 dimensions, (batch_size, sequence_length, input_size)\n",
    "        if generated.dim() == 2:  # If context is 2D, add a dummy feature dimension\n",
    "            generated = generated.unsqueeze(-1)  # (batch_size, sequence_length, 1)\n",
    "            print(f\"After unsqueeze: {generated.shape}\")  # Debugging\n",
    "\n",
    "        # Now, check if the context has the right number of features (9), and expand if necessary\n",
    "        if generated.size(-1) != 9:\n",
    "            print(f\"Before expand: {generated.shape}\")  # Debugging\n",
    "            generated = generated.expand(-1, -1, 9)  # Expand to match 9 features\n",
    "            print(f\"After expand: {generated.shape}\")  # Debugging\n",
    "\n",
    "        # Now we are ready to generate new tokens\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Forward pass through the LSTM\n",
    "            lstm_out, _ = self.lstm(generated)\n",
    "            \n",
    "            # Get the output from the last time step (predicted token)\n",
    "            output = self.fc(lstm_out[:, -1, :])  # Pass through the fully connected layer\n",
    "            next_token = output.argmax(dim=-1)  # Choose the token with the highest probability\n",
    "            \n",
    "            # Append the generated token to the context for the next step\n",
    "            next_token_expanded = next_token.unsqueeze(0).unsqueeze(-1).float()  # Convert to float32 and add necessary dimensions\n",
    "            generated = torch.cat((generated, next_token_expanded.expand(-1, -1, 9)), dim=1)  # Add the new token to context\n",
    "\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "# Ensure both model and input tensor are on the same device\n",
    "context = torch.randn((1, 1, 9), dtype=torch.float32, device=device)\n",
    "\n",
    "# Ensure the model is on the same device\n",
    "best_model.to(device)\n",
    "\n",
    "# Generate the output from the model\n",
    "generated_output = best_model.generate(context, max_new_tokens=500)\n",
    "\n",
    "# Flatten the output and ensure it's a list of indices by using argmax\n",
    "generated_tokens = generated_output[0].flatten().argmax(dim=-1).tolist()\n",
    "\n",
    "# Make sure generated_tokens is a list\n",
    "if not isinstance(generated_tokens, list):\n",
    "    generated_tokens = [generated_tokens]\n",
    "\n",
    "# Decode the generated tokens\n",
    "generated_chars = decode(generated_tokens)\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know it still is unreadable, but if you notice, the letters are making more and more sense. And, you might actually catch a couple words here and there if you run it a couple of times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
